---
title: "Regression Model for Metro Interstate Traffic Volume Using R Take 3"
author: "David Lowe"
date: "September 2, 2019"
output: 
  html_document: 
    toc: yes
    self_contained: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Template Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery. [http://machinelearningmastery.com/]

SUMMARY: The purpose of this project is to construct a predictive model using various machine learning algorithms and to document the end-to-end steps using a template. The Metro Interstate Traffic Volume is a regression situation where we are trying to predict a real-number value for a given set of criteria.

INTRODUCTION: This dataset captured the hourly measurement of Interstate 94 Westbound traffic volume for MN DoT ATR station 301. The station is roughly midway between Minneapolis and St Paul, MN. The dataset also included the hourly weather and holiday attributes for assessing their impacts on traffic volume.

In iteration Take1, we established the baseline mean squared error without much of feature engineering. This round of modeling also did not include the date-time and weather description attributes.

In iteration Take2, we included the time stamp feature and observed its effect on improving the prediction accuracy.

In this iteration, we will re-engineer (scale and/or discretize) the weather-related features and observe their effect on the prediction accuracy.

ANALYSIS: From iteration Take1, the baseline performance of the machine learning algorithms achieved an average RMSE of 2099. Two algorithms (Random Forest and Gradient Boosting) achieved the top RMSE metrics after the first round of modeling. After a series of tuning trials, Gradient Boosting turned in the top overall result and achieved an RMSE metric of 1895. After applying the optimized parameters, the Gradient Boosting algorithm processed the testing dataset with an RMSE of 1899, which was slightly better than the prediction from the training data.

From iteration Take2, the baseline performance of the machine learning algorithms achieved an average RMSE of 972. Two algorithms (Random Forest and Gradient Boosting) achieved the top RMSE metrics after the first round of modeling. After a series of tuning trials, Gradient Boosting turned in the top overall result and achieved an RMSE metric of 480. After applying the optimized parameters, the Gradient Boosting algorithm processed the testing dataset with an RMSE of 479, which was slightly better than the prediction from the training data.

By including the date_time information and related attributes, the machine learning models did a significantly better job in prediction with a much lower RMSE.

In the current iteration, the baseline performance of the machine learning algorithms achieved an average RMSE of 814. Two algorithms (Random Forest and Gradient Boosting) achieved the top RMSE metrics after the first round of modeling. After a series of tuning trials, Gradient Boosting turned in the top overall result and achieved an RMSE metric of 474. After applying the optimized parameters, the Gradient Boosting algorithm processed the testing dataset with an RMSE of 472, which was slightly better than the prediction from the training data.

By re-engineering the weather-related features, the average performance of all models did better. However, the changes appeared to have little impact on the performance of the ensemble algorithms.

CONCLUSION: For this iteration, the Random Forests algorithm achieved the best overall training and validation results. For this dataset, the Random Forests algorithm could be considered for further modeling.

Dataset Used: Metro Interstate Traffic Volume Data Set

Dataset ML Model: Regression with numerical and categorical attributes

Dataset Reference: https://archive.ics.uci.edu/ml/datasets/Metro+Interstate+Traffic+Volume

One potential source of performance benchmarks: https://www.kaggle.com/ramyahr/metro-interstate-traffic-volume

The project aims to touch on the following areas:

1. Document a predictive modeling problem end-to-end.
2. Explore data cleaning and transformation options
3. Explore non-ensemble and ensemble algorithms for baseline model performance
4. Explore algorithm tuning techniques for improving model performance

Any predictive modeling machine learning project genrally can be broken down into about six major tasks:

1. Prepare Environment
2. Summarize Data
3. Prepare Data
4. Model and Evaluate Algorithms
5. Improve Accuracy or Results
6. Finalize Model and Present Results

## 1. Prepare Environment

### 1.a) Load libraries and packages

```{r}
startTimeScript <- proc.time()
library(caret)
library(corrplot)
library(DMwR)
library(Hmisc)
library(ROCR)
library(stringr)
```

### 1.b) Set up the controlling parameters and functions

```{r}
# Create the random seed number for reproducible results
seedNum <- 888

# Set up the notifyStatus flag to stop sending progress emails (setting to TRUE will send status emails!)
notifyStatus <- TRUE
if (notifyStatus) library(mailR)
```

```{r}
# Run algorithms using 10-fold cross validation
control <- trainControl(method="repeatedcv", number=10, repeats=1)
metricTarget <- "RMSE"
```

```{r}
# Set up the email notification function
email_notify <- function(msg=""){
  sender <- Sys.getenv("MAIL_SENDER")
  receiver <- Sys.getenv("MAIL_RECEIVER")
  gateway <- Sys.getenv("SMTP_GATEWAY")
  smtpuser <- Sys.getenv("SMTP_USERNAME")
  password <- Sys.getenv("SMTP_PASSWORD")
  sbj_line <- "Notification from R Regression Modeling Script"
  send.mail(
    from = sender,
    to = receiver,
    subject= sbj_line,
    body = msg,
    smtp = list(host.name = gateway, port = 587, user.name = smtpuser, passwd = password, ssl = TRUE),
    authenticate = TRUE,
    send = TRUE)
}
```

```{r}
if (notifyStatus) email_notify(paste("Library and Data Loading has begun!",date()))
```

### 1.c) Load dataset

```{r}
# Slicing up the document path to get the final destination file name
dataset_path <- 'https://archive.ics.uci.edu/ml/machine-learning-databases/00492/Metro_Interstate_Traffic_Volume.csv.gz'
doc_path_list <- str_split(dataset_path, "/")
# dest_file <- doc_path_list[[1]][length(doc_path_list[[1]])]
dest_file <- "Metro_Interstate_Traffic_Volume.csv"

if (!file.exists(dest_file)) {
  # Download the document from the website
  cat("Downloading", dataset_path, "as", dest_file, "\n")
  download.file(dataset_path, dest_file, mode = "wb")
  cat(dest_file, "downloaded!\n")
  unzip(dest_file)
  cat(dest_file, "unpacked!\n")
}

inputFile <- dest_file
Xy_original <- read.csv(dest_file, header = TRUE)
```

```{r}
# Take a peek at the dataframe after the import
head(Xy_original)
```

```{r}
summary(Xy_original)
```

```{r}
sapply(Xy_original, class)
```

```{r}
sapply(Xy_original, function(x) sum(is.na(x)))
```

### 1.d) Data Cleaning

```{r}
# Create new columns from the date_time attribute
Xy_original$date_time <- strptime(Xy_original$date_time, "%Y-%m-%d %H:%M:%S")
Xy_original$date_month <- months(Xy_original$date_time)
Xy_original$date_month <- as.factor(Xy_original$date_month)
Xy_original$date_weekday <- weekdays(Xy_original$date_time)
Xy_original$date_weekday <- as.factor(Xy_original$date_weekday)
Xy_original$date_hour <- strftime(Xy_original$date_time, "%H")
Xy_original$date_hour <- as.factor(Xy_original$date_hour)
Xy_original$targetVar <- Xy_original$traffic_volume

# Re-engineer the weather related attributes
# Rescale the temperature in Kelvin to Celcius & correct some zero degree Kelvin entries 
mean_temp = mean(Xy_original$temp)
Xy_original$temp[Xy_original$temp == 0] <- mean_temp
Xy_original$temp = Xy_original$temp - 272.15
# Reset one row with rainfall of 9831.3 mm to the max of 55.63
max_rain = 55.63
Xy_original$rain_1h[Xy_original$rain_1h > 100] <- max_rain

# Drop un-needed features
Xy_original$date_time <- NULL
Xy_original$weather_description <- NULL
Xy_original$traffic_volume <- NULL
```

```{r}
# Take a peek at the dataframe after the cleaning
head(Xy_original)
```

```{r}
summary(Xy_original)
```

```{r}
sapply(Xy_original, class)
```

```{r}
sapply(Xy_original, function(x) sum(is.na(x)))
```

### 1.e) Splitting Data into Training and Test Sets

```{r}
# Use variable totCol to hold the number of columns in the dataframe
totCol <- ncol(Xy_original)

# Set up variable totAttr for the total number of attribute columns
totAttr <- totCol-1
```

```{r}
# targetCol variable indicates the column location of the target/class variable
# If the first column, set targetCol to 1. If the last column, set targetCol to totCol
# if (targetCol <> 1) and (targetCol <> totCol), be aware when slicing up the dataframes for visualization! 
targetCol <- totCol

# Standardize the class column to the name of targetVar if applicable
colnames(Xy_original)[targetCol] <- "targetVar"
```

```{r}
# Create various sub-datasets for visualization and cleaning/transformation operations.
set.seed(seedNum)

# Use 75% of the data to train the models and the remaining for testing/validation
training_index <- createDataPartition(Xy_original$targetVar, p=0.75, list=FALSE)
Xy_train <- Xy_original[training_index,]
Xy_test <- Xy_original[-training_index,]

if (targetCol==1) {
  X_train <- Xy_train[,(targetCol+1):totCol]
  y_train <- Xy_train[,targetCol]
  y_test <- Xy_test[,targetCol]
} else {
  X_train <- Xy_train[,1:(totAttr)]
  y_train <- Xy_train[,totCol]
  y_test <- Xy_test[,totCol]
}
```

### 1.f) Set up the parameters for data visualization

```{r}
# Set up the number of row and columns for visualization display. dispRow * dispCol should be >= totAttr
dispCol <- 4
if (totAttr%%dispCol == 0) {
dispRow <- totAttr%/%dispCol
} else {
dispRow <- (totAttr%/%dispCol) + 1
}
cat("Will attempt to create graphics grid (col x row): ", dispCol, ' by ', dispRow)
```

```{r}
if (notifyStatus) email_notify(paste("Library and Data Loading completed!",date()))
```

## 2. Summarize Data
To gain a better understanding of the data that we have on-hand, we will leverage a number of descriptive statistics and data visualization techniques. The plan is to use the results to consider new questions, review assumptions, and validate hypotheses that we can investigate later with specialized models.

```{r}
if (notifyStatus) email_notify(paste("Data Summarization and Visualization has begun!",date()))
```

### 2.a) Descriptive statistics

#### 2.a.i) Peek at the data itself

```{r}
head(Xy_train)
```

#### 2.a.ii) Dimensions of the dataset

```{r}
dim(Xy_train)
```

#### 2.a.iii) Types of the attribute

```{r}
sapply(Xy_train, class)
```

#### 2.a.iv) Statistical summary of the attributes

```{r}
summary(Xy_train)
```

#### 2.a.v) Count missing values

```{r}
sapply(Xy_train, function(x) sum(is.na(x)))
```

### 2.b) Data visualizations

```{r}
# Boxplots for each attribute
# par(mfrow=c(dispRow,dispCol))
# for(i in 1:totAttr) {
# 	boxplot(X_train[,i], main=names(X_train)[i])
# }
```

```{r}
# Histograms each attribute
# par(mfrow=c(dispRow,dispCol))
# for(i in 1:totAttr) {
# 	hist(X_train[,i], main=names(X_train)[i])
# }
```

```{r}
# Density plot for each attribute
# par(mfrow=c(dispRow,dispCol))
# for(i in 1:totAttr) {
# 	plot(density(X_train[,i]), main=names(X_train)[i])
# }
```

```{r}
# Correlation matrix
# correlations <- cor(X_train)
# corrplot(correlations, method="circle")
```

```{r}
if (notifyStatus) email_notify(paste("Data Summarization and Visualization completed!",date()))
```

## 3. Prepare Data
Some dataset may require additional preparation activities that will best exposes the structure of the problem and the relationships between the input attributes and the output variable. Some data-prep tasks might include:

* Cleaning data by removing duplicates, marking missing values and even imputing missing values.
* Feature selection where redundant features may be removed.
* Data transforms where attributes are scaled or redistributed in order to best expose the structure of the problem later to learning algorithms.

```{r}
if (notifyStatus) email_notify(paste("Data Cleaning and Transformation has begun!",date()))
```

### 3.a) Data Pre-Processing

```{r}
# Apply binning techniques with numeric data

rain_intervals = c(-1, 0, 10, 20, 30, 40, 50, 99)
Xy_train$rain_binned = cut(Xy_train$rain_1h, breaks = rain_intervals, ordered_result = TRUE)

snow_intervals = c(-1, 0, 0.25, 0.5, 1)
Xy_train$snow_binned = cut(Xy_train$snow_1h, breaks = snow_intervals, ordered_result = TRUE)

clouds_intervals = c(-1, 0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100)
Xy_train$clouds_binned = cut(Xy_train$clouds_all, breaks = clouds_intervals, ordered_result = TRUE)

Xy_train$rain_1h <- NULL
Xy_train$snow_1h <- NULL
Xy_train$clouds_all <- NULL
head(Xy_train)
```

```{r}
# Apply binning techniques with numeric data

rain_intervals = c(-1, 0, 10, 20, 30, 40, 50, 99)
Xy_test$rain_binned = cut(Xy_test$rain_1h, breaks = rain_intervals, ordered_result = TRUE)

snow_intervals = c(-1, 0, 0.25, 0.5, 1)
Xy_test$snow_binned = cut(Xy_test$snow_1h, breaks = snow_intervals, ordered_result = TRUE)

clouds_intervals = c(-1, 0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100)
Xy_test$clouds_binned = cut(Xy_test$clouds_all, breaks = clouds_intervals, ordered_result = TRUE)

Xy_test$rain_1h <- NULL
Xy_test$snow_1h <- NULL
Xy_test$clouds_all <- NULL
head(Xy_test)
```

### 3.b) Feature Selection

```{r}
# Not applicable for this iteration of the project
```

### 3.c) Display the Final Datasets for Model-Building

```{r}
# We finalize the training and testing datasets for the modeling activities
dim(Xy_train)
dim(Xy_test)
```

```{r}
if (notifyStatus) email_notify(paste("Data Cleaning and Transformation completed!",date()))
```

```{r}
proc.time()-startTimeScript
```

## 4. Model and Evaluate Algorithms
After the data-prep, we next work on finding a workable model by evaluating a subset of machine learning algorithms that are good at exploiting the structure of the dataset. The typical evaluation tasks include:

* Defining test options such as cross validation and the evaluation metric to use.
* Spot checking a suite of linear and nonlinear machine learning algorithms.
* Comparing the estimated accuracy of algorithms.

For this project, we will evaluate four linear, one non-linear, and three ensemble algorithms:

Linear Algorithms: Linear Regression, Ridge, The Lasso, Elasticnet

Non-Linear Algorithm: Decision Trees (CART)

Ensemble Algorithms: Bagged CART, Random Forest, and Gradient Boosting

The random number seed is reset before each run to ensure that the evaluation of each algorithm is performed using the same data splits. It ensures the results are directly comparable.

### 4.a) Generate models using linear algorithms

```{r}
startModeling <- proc.time()
```

```{r LR}
# Linear Regression (Regression)
if (notifyStatus) email_notify(paste("Linear Regression modeling has begun!",date()))
startTimeModule <- proc.time()
set.seed(seedNum)
fit.lm <- train(targetVar~., data=Xy_train, method="lm", metric=metricTarget, trControl=control)
print(fit.lm)
proc.time()-startTimeModule
if (notifyStatus) email_notify(paste("Linear Regression modeling completed!",date()))
```

```{r RIDGE}
# Ridge (Regression)
if (notifyStatus) email_notify(paste("Ridge Regression modeling has begun!",date()))
startTimeModule <- proc.time()
set.seed(seedNum)
fit.ridge <- train(targetVar~., data=Xy_train, method="ridge", metric=metricTarget, trControl=control)
print(fit.ridge)
proc.time()-startTimeModule
if (notifyStatus) email_notify(paste("Ridge Regression modeling completed!",date()))
```

```{r LASSO}
# The Lasso (Regression)
if (notifyStatus) email_notify(paste("The Lasso modeling has begun!",date()))
startTimeModule <- proc.time()
set.seed(seedNum)
fit.lasso <- train(targetVar~., data=Xy_train, method="lasso", metric=metricTarget, trControl=control)
print(fit.lasso)
proc.time()-startTimeModule
if (notifyStatus) email_notify(paste("The Lasso modeling completed!",date()))
```

```{r ENET}
# Elasticnet (Regression)
if (notifyStatus) email_notify(paste("Elasticnet modeling has begun!",date()))
startTimeModule <- proc.time()
set.seed(seedNum)
fit.enet <- train(targetVar~., data=Xy_train, method="enet", metric=metricTarget, trControl=control)
print(fit.enet)
proc.time()-startTimeModule
if (notifyStatus) email_notify(paste("Elasticnet modeling completed!",date()))
```

### 4.b) Generate models using nonlinear algorithms

```{r CART}
# Decision Tree - CART (Regression/Classification)
if (notifyStatus) email_notify(paste("Decision Tree modeling has begun!",date()))
startTimeModule <- proc.time()
set.seed(seedNum)
fit.cart <- train(targetVar~., data=Xy_train, method="rpart", metric=metricTarget, trControl=control)
print(fit.cart)
proc.time()-startTimeModule
if (notifyStatus) email_notify(paste("Decision Tree modeling completed!",date()))
```

### 4.c) Generate models using ensemble algorithms
In this section, we will explore the use and tuning of ensemble algorithms to see whether we can improve the results.

```{r BAGCART}
# Bagged CART (Regression/Classification)
if (notifyStatus) email_notify(paste("Bagged CART modeling has begun!",date()))
startTimeModule <- proc.time()
set.seed(seedNum)
fit.bagcart <- train(targetVar~., data=Xy_train, method="treebag", metric=metricTarget, trControl=control)
print(fit.bagcart)
proc.time()-startTimeModule
if (notifyStatus) email_notify(paste("Bagged CART modeling completed!",date()))
```

```{r RF}
# Random Forest (Regression/Classification)
if (notifyStatus) email_notify(paste("Random Forest modeling has begun!",date()))
startTimeModule <- proc.time()
set.seed(seedNum)
fit.rf <- train(targetVar~., data=Xy_train, method="rf", metric=metricTarget, trControl=control)
print(fit.rf)
proc.time()-startTimeModule
if (notifyStatus) email_notify(paste("Random Forest modeling completed!",date()))
```

```{r GBM}
# Gradient Boosting (Regression/Classification)
if (notifyStatus) email_notify(paste("Gradient Boosting modeling has begun!",date()))
startTimeModule <- proc.time()
set.seed(seedNum)
fit.gbm <- train(targetVar~., data=Xy_train, method="xgbTree", metric=metricTarget, trControl=control, verbose=F)
# fit.gbm <- train(targetVar~., data=Xy_train, method="gbm", metric=metricTarget, trControl=control, verbose=F)
print(fit.gbm)
proc.time()-startTimeModule
if (notifyStatus) email_notify(paste("Gradient Boosting modeling completed!",date()))
```

### 4.d) Compare baseline algorithms

```{r SPOT_CHECK}
results <- resamples(list(LR=fit.lm, RIDGE=fit.ridge, LASSO=fit.lasso, ENET=fit.enet, CART=fit.cart, BagCART=fit.bagcart, RF=fit.rf, GBM=fit.gbm))
summary(results)
dotplot(results)
cat('The average RMSE from all models is:',
    mean(c(results$values$`LR~RMSE`,results$values$`RIDGE~RMSE`,results$values$`LASSO~RMSE`,results$values$`ENET~RMSE`,results$values$`CART~RMSE`,results$values$`BagCART~RMSE`,results$values$`RF~RMSE`,results$values$`GBM~RMSE`)),'\n')
cat('Total training time for all models:',proc.time()-startModeling)
```

## 5. Improve Accuracy or Results
After we achieve a short list of machine learning algorithms with good level of accuracy, we can leverage ways to improve the accuracy of the models.

Using the three best-perfoming algorithms from the previous section, we will Search for a combination of parameters for each algorithm that yields the best results.

### 5.a) Algorithm Tuning
Finally, we will tune the best-performing algorithms from each group further and see whether we can get more accuracy out of them.

```{r FINAL1}
# Tuning algorithm #1 - Random Forest
if (notifyStatus) email_notify(paste("Algorithm #1 tuning has begun!",date()))
startTimeModule <- proc.time()
set.seed(seedNum)
grid <- expand.grid(mtry = c(2,21,41,61,81))
fit.final1 <- train(targetVar~., data=Xy_train, method="rf", metric=metricTarget, tuneGrid=grid, trControl=control)
plot(fit.final1)
print(fit.final1)
proc.time()-startTimeModule
if (notifyStatus) email_notify(paste("Algorithm #1 tuning completed!",date()))
```

```{r FINAL2}
# Tuning algorithm #2 - Gradient Boosting
if (notifyStatus) email_notify(paste("Algorithm #2 tuning has begun!",date()))
startTimeModule <- proc.time()
set.seed(seedNum)
grid <- expand.grid(nrounds=c(600,700,800,900,1000), max_depth=3, eta=0.4, gamma=0, colsample_bytree=0.8, min_child_weight=1, subsample=0.5)
fit.final2 <- train(targetVar~., data=Xy_train, method="xgbTree", metric=metricTarget, tuneGrid=grid, trControl=control, verbose=F)
plot(fit.final2)
print(fit.final2)
proc.time()-startTimeModule
if (notifyStatus) email_notify(paste("Algorithm #2 tuning completed!",date()))
```

### 5.d) Compare Algorithms After Tuning

```{r POST_TUNING}
results <- resamples(list(RF=fit.final1, GBM=fit.final2))
summary(results)
dotplot(results)
```

## 6. Finalize Model and Present Results
Once we have narrow down to a model that we believe can make accurate predictions on unseen data, we are ready to finalize it. Finalizing a model may involve sub-tasks such as:

* Using an optimal model tuned to make predictions on unseen data.
* Creating a standalone model using the tuned parameters
* Saving an optimal model to file for later use.

```{r}
if (notifyStatus) email_notify(paste("Model Validation and Final Model Creation has begun!",date()))
```

### 6.a) Predictions on validation dataset

```{r PREDICT1}
predictions <- predict(fit.final1, newdata=Xy_test)
cat("The RMSE for the test data is:", RMSE(predictions, y_test),'\n')
cat("The R2 score for the model is:", R2(predictions, y_test))
```

```{r PREDICT2}
predictions <- predict(fit.final2, newdata=Xy_test)
cat("The RMSE for the test data is:", RMSE(predictions, y_test),'\n')
cat("The R2 score for the model is:", R2(predictions, y_test))
```

### 6.b) Create standalone model on entire training dataset

```{r FINALMODEL}
startTimeModule <- proc.time()
set.seed(seedNum)

# Combining datasets to form a complete dataset that will be used to train the final model
Xy_complete <- rbind(Xy_train, Xy_test)

# library(xgboost)
# finalModel <- xgboost(data=Xy_complete, label=Xy_complete$targetVar, nrounds=900, max_depth=3, eta=0.4, gamma=0, colsample_bytree=0.8, min_child_weight=1, subsample=0.5)
# summary(finalModel)
proc.time()-startTimeModule
```

### 6.c) Save model for later use

```{r}
#saveRDS(finalModel, "./finalModel_Regression.rds")
```

```{r}
if (notifyStatus) email_notify(paste("Model Validation and Final Model Creation Completed!",date()))
proc.time()-startTimeScript
```
