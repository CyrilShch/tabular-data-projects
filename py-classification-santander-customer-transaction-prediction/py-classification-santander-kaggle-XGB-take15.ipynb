{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification Model for Customer Transaction Prediction Using Python (eXtreme Gradient Boosting Batch Testing) Take 15\n",
    "### David Lowe\n",
    "### April 10, 2019\n",
    "\n",
    "Template Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery. [https://machinelearningmastery.com/]\n",
    "\n",
    "SUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The Santander Bank Customer Transaction Prediction competition is a binary classification situation where we are trying to predict one of the two possible outcomes.\n",
    "\n",
    "INTRODUCTION: Santander Bank's data science team wants to identify which customers will make a specific transaction in the future, irrespective of the amount of money transacted. The bank is continually challenging its machine learning algorithms to make sure they can more accurately identify new ways to solve its most common challenges such as: Will a customer buy this product? Can a customer pay this loan?\n",
    "\n",
    "For this iteration, we will examine the effectiveness of the eXtreme Gradient Boosting (XGBoost) algorithm with the synthetic over-sampling technique (SMOTE) to mitigate the effect of imbalanced data for this problem. Submissions are evaluated on the area under the ROC curve between the predicted probability and the observed target.\n",
    "\n",
    "ANALYSIS: The performance from the training dataset achieved an average ROC-AUC score of 0.????.\n",
    "\n",
    "CONCLUSION: After submitting the test dataset to Kaggle, the trained model processed the test dataset with a ROC-AUC score of 0.????.\n",
    "\n",
    "Dataset Used: Santander Customer Transaction Prediction\n",
    "\n",
    "Dataset ML Model: Binary classification with numerical attributes\n",
    "\n",
    "Dataset Reference: https://www.kaggle.com/c/santander-customer-transaction-prediction/data\n",
    "\n",
    "One potential source of performance benchmark: https://www.kaggle.com/c/santander-customer-transaction-prediction/overview\n",
    "\n",
    "The project aims to touch on the following areas:\n",
    "\n",
    "* Document a predictive modeling problem end-to-end.\n",
    "* Explore data cleaning and transformation options\n",
    "* Explore non-ensemble and ensemble algorithms for baseline model performance\n",
    "* Explore algorithm tuning techniques for improving model performance\n",
    "\n",
    "Any predictive modeling machine learning project genrally can be broken down into about six major tasks:\n",
    "\n",
    "1. Prepare Problem\n",
    "2. Summarize Data\n",
    "3. Prepare Data\n",
    "4. Model and Evaluate Algorithms\n",
    "5. Improve Accuracy or Results\n",
    "6. Finalize Model and Present Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 - Prepare Problem\n",
    "### 1.a) Load ibraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import warnings\n",
    "import smtplib\n",
    "from datetime import datetime\n",
    "from email.message import EmailMessage\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import get_dummies\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.externals.joblib import dump\n",
    "from sklearn.externals.joblib import load\n",
    "from sklearn.feature_selection import RFE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# from imblearn.combine import SMOTEENN\n",
    "# from imblearn.combine import SMOTETomek\n",
    "\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.ensemble import BaggingClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.ensemble import ExtraTreesClassifier\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "# from imblearn.ensemble import RUSBoostClassifier\n",
    "# from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Create one random seed number for reproducible results\n",
    "seedNum = 888"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.b) Set up the email notification function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_notify(msg_text):\n",
    "    sender = os.environ.get('MAIL_USERNAME')\n",
    "    password = os.environ.get('MAIL_PASSWORD')\n",
    "    receiver = os.environ.get('RECEIVER_MAIL')\n",
    "    if sender==None or password==None or receiver==None :\n",
    "        sys.exit(\"Incomplete email setup info. Script Processing Aborted!!!\")\n",
    "    msg = EmailMessage()\n",
    "    msg.set_content(msg_text)\n",
    "    msg['Subject'] = 'Notification from Python Binary Classification Script'\n",
    "    msg['From'] = sender\n",
    "    msg['To'] = receiver\n",
    "    server = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "    server.starttls()\n",
    "    server.login(sender, password)\n",
    "    server.send_message(msg)\n",
    "    server.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_notify(\"Library and Data Loading has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.c) Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
      "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
      "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
      "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
      "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
      "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
      "\n",
      "     var_7   ...     var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
      "0  18.6266   ...      4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
      "1  16.5338   ...      7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
      "2  14.6155   ...      2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
      "3  14.9250   ...      4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
      "4  19.2514   ...     -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
      "\n",
      "   var_196  var_197  var_198  var_199  \n",
      "0   7.8784   8.5635  12.7803  -1.0914  \n",
      "1   8.1267   8.7889  18.3560   1.9518  \n",
      "2  -6.5213   8.2675  14.7222   0.3965  \n",
      "3  -2.9275  10.2922  17.9697  -8.9996  \n",
      "4   3.9267   9.5031  17.9974  -8.8104  \n",
      "\n",
      "[5 rows x 202 columns]\n"
     ]
    }
   ],
   "source": [
    "startTimeScript = datetime.now()\n",
    "\n",
    "inputFile = 'train.csv'\n",
    "x_original_df = read_csv(inputFile, sep=',', index_col=False)\n",
    "print(x_original_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   target    var_0   var_1    var_2   var_3    var_4   var_5   var_6    var_7  \\\n",
      "0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187  18.6266   \n",
      "1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208  16.5338   \n",
      "2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427  14.6155   \n",
      "3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428  14.9250   \n",
      "4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405  19.2514   \n",
      "\n",
      "    var_8   ...     var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
      "0 -4.9200   ...      4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
      "1  3.1468   ...      7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
      "2 -4.9193   ...      2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
      "3 -5.8609   ...      4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
      "4  6.2654   ...     -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
      "\n",
      "   var_196  var_197  var_198  var_199  \n",
      "0   7.8784   8.5635  12.7803  -1.0914  \n",
      "1   8.1267   8.7889  18.3560   1.9518  \n",
      "2  -6.5213   8.2675  14.7222   0.3965  \n",
      "3  -2.9275  10.2922  17.9697  -8.9996  \n",
      "4   3.9267   9.5031  17.9974  -8.8104  \n",
      "\n",
      "[5 rows x 201 columns]\n"
     ]
    }
   ],
   "source": [
    "x_original_df.drop('ID_code',axis=1,inplace=True)\n",
    "print(x_original_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_original_df = x_original_df.iloc[:,0]\n",
    "print(y_original_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var_0   var_1    var_2   var_3    var_4   var_5   var_6    var_7   var_8  \\\n",
      "0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187  18.6266 -4.9200   \n",
      "1  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208  16.5338  3.1468   \n",
      "2   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427  14.6155 -4.9193   \n",
      "3  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428  14.9250 -5.8609   \n",
      "4   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405  19.2514  6.2654   \n",
      "\n",
      "    var_9   ...     var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
      "0  5.7470   ...      4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
      "1  8.0851   ...      7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
      "2  5.9525   ...      2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
      "3  8.2450   ...      4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
      "4  7.6784   ...     -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
      "\n",
      "   var_196  var_197  var_198  var_199  \n",
      "0   7.8784   8.5635  12.7803  -1.0914  \n",
      "1   8.1267   8.7889  18.3560   1.9518  \n",
      "2  -6.5213   8.2675  14.7222   0.3965  \n",
      "3  -2.9275  10.2922  17.9697  -8.9996  \n",
      "4   3.9267   9.5031  17.9974  -8.8104  \n",
      "\n",
      "[5 rows x 200 columns]\n"
     ]
    }
   ],
   "source": [
    "x_original_df.drop('target',axis=1,inplace=True)\n",
    "print(x_original_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_original_df.shape: (200000, 200) y_original_df.shape: (200000,)\n",
      "x_train_df.shape: (140000, 200) y_train_df.shape: (140000,)\n",
      "x_test_df.shape: (60000, 200) y_test_df.shape: (60000,)\n"
     ]
    }
   ],
   "source": [
    "# Use 70% of the data to train the models and the remaining for testing/validation\n",
    "validation_size = 0.30\n",
    "x_train_df, x_test_df, y_train_df, y_test_df = train_test_split(x_original_df, y_original_df, test_size=validation_size, random_state=seedNum)\n",
    "print(\"x_original_df.shape: {} y_original_df.shape: {}\".format(x_original_df.shape, y_original_df.shape))\n",
    "print(\"x_train_df.shape: {} y_train_df.shape: {}\".format(x_train_df.shape, y_train_df.shape))\n",
    "print(\"x_test_df.shape: {} y_test_df.shape: {}\".format(x_test_df.shape, y_test_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_notify(\"Library and Data Loading completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 - Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_notify(\"Data Cleaning and Transformation has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.a) Data Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_imbal.shape: (140000, 200) y_train_imbal.shape: (140000,)\n"
     ]
    }
   ],
   "source": [
    "# Sample code for performing SMOTE transformation on the training data (Block #1 of 2)\n",
    "x_train_imbal = x_train_df.values\n",
    "y_train_imbal = y_train_df.values.ravel()\n",
    "print(\"x_train_imbal.shape: {} y_train_imbal.shape: {}\".format(x_train_imbal.shape, y_train_imbal.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution - 1: 14199 | 0: 125801\n",
      "Resampled class distribution - 1: 125801 | 0: 125801\n"
     ]
    }
   ],
   "source": [
    "# Sample code for performing SMOTE transformation on the training data (Block #2 of 2)\n",
    "print ('Original class distribution - 1: {} | 0: {}'.format((y_train_imbal==1).sum(), (y_train_imbal==0).sum()))\n",
    "sm = SMOTE(random_state=seedNum, sampling_strategy=1.0)\n",
    "x_train, y_train = sm.fit_resample(x_train_imbal, y_train_imbal)\n",
    "print ('Resampled class distribution - 1: {} | 0: {}'.format((y_train==1).sum(), (y_train==0).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.b) Display the Final Datasets for Model-Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (251602, 200) y_train.shape: (251602,)\n",
      "x_test.shape: (60000, 200) y_test.shape: (60000,)\n"
     ]
    }
   ],
   "source": [
    "# We finalize the training and testing datasets for the modeling activities\n",
    "x_test = x_test_df.values\n",
    "y_test = y_test_df.values.ravel()\n",
    "print(\"x_train.shape: {} y_train.shape: {}\".format(x_train.shape, y_train.shape))\n",
    "print(\"x_test.shape: {} y_test.shape: {}\".format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_notify(\"Data Cleaning and Transformation completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3 - Model Building and Finalizing Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_notify(\"Model Building and Finalizing Output has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.a) Set test options and evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run algorithms using 10-fold cross validation\n",
    "num_folds = 10\n",
    "scoring = 'roc_auc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the comparison array\n",
    "models = []\n",
    "results = []\n",
    "names = []\n",
    "metrics = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.b) Algorithm Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_complete.shape: (311602, 200) y_complete.shape: (311602,)\n"
     ]
    }
   ],
   "source": [
    "startTimeModule = datetime.now()\n",
    "\n",
    "# Combining the training and testing datasets to form the complete dataset that will be used for training the final model\n",
    "x_complete = np.vstack((x_train, x_test))\n",
    "y_complete = np.concatenate((y_train, y_test))\n",
    "print(\"x_complete.shape: {} y_complete.shape: {}\".format(x_complete.shape, y_complete.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training time: 0:57:38.307930\n"
     ]
    }
   ],
   "source": [
    "finalModel = XGBClassifier(random_state=seedNum, n_jobs=6, max_depth=6, learning_rate=0.01, n_estimators=1000)\n",
    "finalModel.fit(x_complete, y_complete)\n",
    "print ('Model training time:',(datetime.now() - startTimeModule))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.c) Finalizing Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ID_code    var_0    var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
      "0  test_0  11.0656   7.7798  12.9536  9.4292  11.4327 -2.3805  5.8493   \n",
      "1  test_1   8.5304   1.2543  11.3047  5.1858   9.1974 -4.0117  6.0196   \n",
      "2  test_2   5.4827 -10.3581  10.1407  7.0479  10.2628  9.8052  4.8950   \n",
      "3  test_3   8.5374  -1.3222  12.0220  6.5749   8.8458  3.1744  4.9397   \n",
      "4  test_4  11.7058  -0.1327  14.1295  7.7506   9.1035 -8.5848  6.8595   \n",
      "\n",
      "     var_7   var_8   ...     var_190  var_191  var_192  var_193  var_194  \\\n",
      "0  18.2675  2.1337   ...     -2.1556  11.8495  -1.4300   2.4508  13.7112   \n",
      "1  18.6316 -4.4131   ...     10.6165   8.8349   0.9403  10.1282  15.5765   \n",
      "2  20.2537  1.5233   ...     -0.7484  10.9935   1.9803   2.1800  12.9813   \n",
      "3  20.5660  3.3755   ...      9.5702   9.0766   1.6580   3.5813  15.1874   \n",
      "4  10.6048  2.9890   ...      4.2259   9.1723   1.2835   3.3778  19.5542   \n",
      "\n",
      "   var_195  var_196  var_197  var_198  var_199  \n",
      "0   2.4669   4.3654  10.7200  15.4722  -8.7197  \n",
      "1   0.4773  -1.4852   9.8714  19.1293 -20.9760  \n",
      "2   2.1281  -7.1086   7.0618  19.8956 -23.1794  \n",
      "3   3.1656   3.9567   9.2295  13.0168  -4.2108  \n",
      "4  -0.2860  -5.1612   7.2882  13.9260  -9.1846  \n",
      "\n",
      "[5 rows x 201 columns]\n"
     ]
    }
   ],
   "source": [
    "inputFile = 'test.csv'\n",
    "x_validation_df = read_csv(inputFile, sep=',', index_col=False)\n",
    "print(x_validation_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_validation.shape: (200000, 200)\n"
     ]
    }
   ],
   "source": [
    "y_submission_df = pd.DataFrame(columns=['ID_code','target'])\n",
    "y_submission_df['ID_code'] = x_validation_df['ID_code']\n",
    "x_validation_df.drop('ID_code',axis=1,inplace=True)\n",
    "x_validation = x_validation_df.values\n",
    "print(\"x_validation.shape: {}\".format(x_validation.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_submission_df.shape: (200000, 2)\n"
     ]
    }
   ],
   "source": [
    "predictions = finalModel.predict(x_validation)\n",
    "y_submission_df['target'] = predictions\n",
    "print(\"y_submission_df.shape: {}\".format(y_submission_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ID_code  target\n",
      "0  test_0       0\n",
      "1  test_1       0\n",
      "2  test_2       0\n",
      "3  test_3       0\n",
      "4  test_4       0\n"
     ]
    }
   ],
   "source": [
    "print(y_submission_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    187890\n",
       "1     12110\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_submission_df.groupby('target').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = y_submission_df.to_csv(header=True,index=False)\n",
    "filename = 'submission_' + datetime.now().strftime('%Y%m%d-%H%M') + '.csv'\n",
    "with open(filename, 'w') as f:\n",
    "    f.write(out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_notify(\"Model Building and Finalizing Output completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time for the script: 1:00:04.854868\n"
     ]
    }
   ],
   "source": [
    "print ('Total time for the script:',(datetime.now() - startTimeScript))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
