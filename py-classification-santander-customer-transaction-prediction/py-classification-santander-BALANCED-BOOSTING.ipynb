{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification Model for Customer Transaction Prediction Using Python (Balanced Boosting)\n",
    "### David Lowe\n",
    "### March 27, 2019\n",
    "\n",
    "Template Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery. [https://machinelearningmastery.com/]\n",
    "\n",
    "SUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The Santander Bank Customer Transaction Prediction competition is a binary classification situation where we are trying to predict one of the two possible outcomes.\n",
    "\n",
    "INTRODUCTION: Santander Bank's data science team wants to identify which customers will make a specific transaction in the future, irrespective of the amount of money transacted. The bank is continually challenging its machine learning algorithms to make sure they can more accurately identify new ways to solve its most common challenges such as: Will a customer buy this product? Can a customer pay this loan?\n",
    "\n",
    "For this iteration, we will examine the effectiveness of the Balanced Boosting classifier (from the imbalanced-learn package) with inner balancing samplers to mitigate the effect of imbalanced data for this problem. Submissions are evaluated on the area under the ROC curve between the predicted probability and the observed target.\n",
    "\n",
    "ANALYSIS: The baseline performance achieved an average ROC-AUC score of 0.6844. After a series of tuning trials, the top result from the training data was a ROC-AUC score of 0.6860. By using the optimized parameters, the algorithm processed the test dataset with a ROC-AUC score of 0.5681.\n",
    "\n",
    "CONCLUSION: To be determined after comparing the results from other machine learning algorithms.\n",
    "\n",
    "Dataset Used: Santander Customer Transaction Prediction\n",
    "\n",
    "Dataset ML Model: Binary classification with numerical attributes\n",
    "\n",
    "Dataset Reference: https://www.kaggle.com/c/santander-customer-transaction-prediction/data\n",
    "\n",
    "One potential source of performance benchmark: https://www.kaggle.com/c/santander-customer-transaction-prediction/overview\n",
    "\n",
    "The project aims to touch on the following areas:\n",
    "\n",
    "* Document a predictive modeling problem end-to-end.\n",
    "* Explore data cleaning and transformation options\n",
    "* Explore non-ensemble and ensemble algorithms for baseline model performance\n",
    "* Explore algorithm tuning techniques for improving model performance\n",
    "\n",
    "Any predictive modeling machine learning project genrally can be broken down into about six major tasks:\n",
    "\n",
    "1. Prepare Problem\n",
    "2. Summarize Data\n",
    "3. Prepare Data\n",
    "4. Model and Evaluate Algorithms\n",
    "5. Improve Accuracy or Results\n",
    "6. Finalize Model and Present Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 - Prepare Problem\n",
    "### 1.a) Load ibraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import warnings\n",
    "import smtplib\n",
    "from datetime import datetime\n",
    "from email.message import EmailMessage\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import get_dummies\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.externals.joblib import dump\n",
    "from sklearn.externals.joblib import load\n",
    "from sklearn.feature_selection import RFE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "\n",
    "# Create one random seed number for reproducible results\n",
    "seedNum = 888"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.b) Set up the email notification function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_notify(msg_text):\n",
    "    sender = \"luozhi2488@gmail.com\"\n",
    "    receiver = \"dave@contactdavidlowe.com\"\n",
    "    with open('../../email_credential.txt') as f:\n",
    "        password = f.readline()\n",
    "        f.close()\n",
    "    msg = EmailMessage()\n",
    "    msg.set_content(msg_text)\n",
    "    msg['Subject'] = 'Notification from Python Binary Classification Script'\n",
    "    msg['From'] = sender\n",
    "    msg['To'] = receiver\n",
    "    server = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "    server.starttls()\n",
    "    server.login(sender, password)\n",
    "    server.send_message(msg)\n",
    "    server.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_notify(\"Library and Data Loading has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.c) Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTimeScript = datetime.now()\n",
    "\n",
    "dataset_path = 'https://www.kaggle.com/c/santander-customer-transaction-prediction/download/train.csv'\n",
    "dest_file = os.path.basename(dataset_path)\n",
    "# if (os.path.isfile(dest_file) == False) :\n",
    "#     print('Downloading ' + dataset_path + ' as ' + dest_file)\n",
    "#     with urllib.request.urlopen(dataset_path) as in_resp, open(dest_file, 'wb') as out_file:\n",
    "#         shutil.copyfileobj(in_resp, out_file)\n",
    "#     print(dest_file + 'downloaded!')\n",
    "#     print('Unpacking ' + dest_file)\n",
    "#     with zipfile.ZipFile(dest_file, 'r') as zip_ref:\n",
    "#         zip_ref.extractall('.')\n",
    "#     print(dest_file + 'unpacked!')\n",
    "\n",
    "inputFile = dest_file\n",
    "xy_original_df = read_csv(inputFile, sep=',', index_col=False)\n",
    "xy_original_df.drop('ID_code',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use variable totCol to hold the number of columns in the dataframe\n",
    "totCol = len(xy_original_df.columns)\n",
    "\n",
    "# Set up variable totAttr for the total number of attribute columns\n",
    "totAttr = totCol-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targetCol variable indicates the column location of the target/class variable\n",
    "# If the first column, set targetCol to 1. If the last column, set targetCol to totCol\n",
    "# If (targetCol <> 1) and (targetCol <> totCol), be aware when slicing up the dataframes for visualization\n",
    "targetCol = 1\n",
    "\n",
    "# Standardize the class column to the name of targetVar if required\n",
    "xy_original_df = xy_original_df.rename(columns={'target': 'targetVar'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xy_original_df.shape: (200000, 201) xy_train_df.shape: (140000, 201)\n",
      "x_train_df.shape: (140000, 200) y_train_df.shape: (140000,)\n",
      "x_test_df.shape: (60000, 200) y_test_df.shape: (60000,)\n"
     ]
    }
   ],
   "source": [
    "# We create training datasets (xy_train_df, x_train_df, y_train_df) for various visualization and cleaning/transformation operations\n",
    "# We create testing datasets (x_test_df, y_test_df) for various visualization and cleaning/transformation operations\n",
    "# Use 70% of the data to train the models and the remaining for testing/validation\n",
    "\n",
    "if targetCol == totCol:\n",
    "    x_original_df = xy_original_df.iloc[:,0:totAttr]\n",
    "    y_original_df = xy_original_df.iloc[:,totAttr]\n",
    "else:\n",
    "    x_original_df = xy_original_df.iloc[:,1:totCol]\n",
    "    y_original_df = xy_original_df.iloc[:,0]\n",
    "\n",
    "validation_size = 0.30\n",
    "x_train_df, x_test_df, y_train_df, y_test_df = train_test_split(x_original_df, y_original_df, test_size=validation_size, random_state=seedNum)\n",
    "xy_train_df = pd.concat([x_train_df, y_train_df], axis=1)\n",
    "print(\"xy_original_df.shape: {} xy_train_df.shape: {}\".format(xy_original_df.shape, xy_train_df.shape))\n",
    "print(\"x_train_df.shape: {} y_train_df.shape: {}\".format(x_train_df.shape, y_train_df.shape))\n",
    "print(\"x_test_df.shape: {} y_test_df.shape: {}\".format(x_test_df.shape, y_test_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.d) Set up the key parameters to be used in the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the number of row and columns for visualization display. dispRow * dispCol should be >= totAttr\n",
    "dispCol = 3\n",
    "if totAttr % dispCol == 0 :\n",
    "    dispRow = totAttr // dispCol\n",
    "else :\n",
    "    dispRow = (totAttr // dispCol) + 1\n",
    "    \n",
    "# Set figure width to 16 and height to 12 (4:3 aspect ratio)\n",
    "fig_size = pyplot.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 16\n",
    "fig_size[1] = 12\n",
    "pyplot.rcParams[\"figure.figsize\"] = fig_size\n",
    "\n",
    "# Set the warning message filter\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_notify(\"Library and Data Loading completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 - Summarize Data\n",
    "To gain a better understanding of the data that we have on-hand, we will leverage a number of descriptive statistics and data visualization techniques. The plan is to use the results to consider new questions, review assumptions, and validate hypotheses that we can investigate later with specialized models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_notify(\"Data Summarization and Visualization has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.a) Descriptive statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.a.i) Peek at the data itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "      <th>targetVar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62824</th>\n",
       "      <td>9.3297</td>\n",
       "      <td>-2.2958</td>\n",
       "      <td>13.8450</td>\n",
       "      <td>6.7170</td>\n",
       "      <td>11.1910</td>\n",
       "      <td>-6.3281</td>\n",
       "      <td>3.6014</td>\n",
       "      <td>15.3160</td>\n",
       "      <td>-2.1185</td>\n",
       "      <td>6.1505</td>\n",
       "      <td>...</td>\n",
       "      <td>9.1690</td>\n",
       "      <td>1.5574</td>\n",
       "      <td>6.6926</td>\n",
       "      <td>22.2004</td>\n",
       "      <td>0.4653</td>\n",
       "      <td>-0.9314</td>\n",
       "      <td>7.3704</td>\n",
       "      <td>13.9909</td>\n",
       "      <td>-11.1948</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35463</th>\n",
       "      <td>8.8205</td>\n",
       "      <td>-5.1823</td>\n",
       "      <td>13.4572</td>\n",
       "      <td>6.3583</td>\n",
       "      <td>9.8454</td>\n",
       "      <td>-7.0326</td>\n",
       "      <td>5.3683</td>\n",
       "      <td>19.2255</td>\n",
       "      <td>-0.8516</td>\n",
       "      <td>6.1638</td>\n",
       "      <td>...</td>\n",
       "      <td>9.3949</td>\n",
       "      <td>6.1643</td>\n",
       "      <td>4.2330</td>\n",
       "      <td>18.8487</td>\n",
       "      <td>-0.3255</td>\n",
       "      <td>6.2714</td>\n",
       "      <td>7.6188</td>\n",
       "      <td>10.2298</td>\n",
       "      <td>5.9419</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51579</th>\n",
       "      <td>7.2094</td>\n",
       "      <td>5.6705</td>\n",
       "      <td>8.9917</td>\n",
       "      <td>2.4625</td>\n",
       "      <td>10.6040</td>\n",
       "      <td>-7.6758</td>\n",
       "      <td>5.6306</td>\n",
       "      <td>21.5245</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>5.3397</td>\n",
       "      <td>...</td>\n",
       "      <td>10.1736</td>\n",
       "      <td>1.3238</td>\n",
       "      <td>-0.8232</td>\n",
       "      <td>14.9173</td>\n",
       "      <td>1.0350</td>\n",
       "      <td>9.7769</td>\n",
       "      <td>7.1368</td>\n",
       "      <td>19.6281</td>\n",
       "      <td>0.8843</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165164</th>\n",
       "      <td>10.2260</td>\n",
       "      <td>-8.8893</td>\n",
       "      <td>11.3938</td>\n",
       "      <td>8.1316</td>\n",
       "      <td>8.4619</td>\n",
       "      <td>-8.6174</td>\n",
       "      <td>6.3148</td>\n",
       "      <td>20.8304</td>\n",
       "      <td>-1.8230</td>\n",
       "      <td>7.1246</td>\n",
       "      <td>...</td>\n",
       "      <td>5.5738</td>\n",
       "      <td>1.9381</td>\n",
       "      <td>-5.1487</td>\n",
       "      <td>16.9208</td>\n",
       "      <td>-1.2639</td>\n",
       "      <td>3.4729</td>\n",
       "      <td>8.1272</td>\n",
       "      <td>15.0752</td>\n",
       "      <td>-6.8129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125207</th>\n",
       "      <td>6.5347</td>\n",
       "      <td>0.3578</td>\n",
       "      <td>7.9561</td>\n",
       "      <td>3.0195</td>\n",
       "      <td>11.4697</td>\n",
       "      <td>-12.9661</td>\n",
       "      <td>3.8820</td>\n",
       "      <td>16.2908</td>\n",
       "      <td>2.4811</td>\n",
       "      <td>6.5964</td>\n",
       "      <td>...</td>\n",
       "      <td>14.9574</td>\n",
       "      <td>3.1190</td>\n",
       "      <td>0.6334</td>\n",
       "      <td>17.9840</td>\n",
       "      <td>-0.6914</td>\n",
       "      <td>7.3110</td>\n",
       "      <td>9.4617</td>\n",
       "      <td>16.9748</td>\n",
       "      <td>6.4416</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          var_0   var_1    var_2   var_3    var_4    var_5   var_6    var_7  \\\n",
       "62824    9.3297 -2.2958  13.8450  6.7170  11.1910  -6.3281  3.6014  15.3160   \n",
       "35463    8.8205 -5.1823  13.4572  6.3583   9.8454  -7.0326  5.3683  19.2255   \n",
       "51579    7.2094  5.6705   8.9917  2.4625  10.6040  -7.6758  5.6306  21.5245   \n",
       "165164  10.2260 -8.8893  11.3938  8.1316   8.4619  -8.6174  6.3148  20.8304   \n",
       "125207   6.5347  0.3578   7.9561  3.0195  11.4697 -12.9661  3.8820  16.2908   \n",
       "\n",
       "         var_8   var_9    ...      var_191  var_192  var_193  var_194  \\\n",
       "62824  -2.1185  6.1505    ...       9.1690   1.5574   6.6926  22.2004   \n",
       "35463  -0.8516  6.1638    ...       9.3949   6.1643   4.2330  18.8487   \n",
       "51579   0.7456  5.3397    ...      10.1736   1.3238  -0.8232  14.9173   \n",
       "165164 -1.8230  7.1246    ...       5.5738   1.9381  -5.1487  16.9208   \n",
       "125207  2.4811  6.5964    ...      14.9574   3.1190   0.6334  17.9840   \n",
       "\n",
       "        var_195  var_196  var_197  var_198  var_199  targetVar  \n",
       "62824    0.4653  -0.9314   7.3704  13.9909 -11.1948          0  \n",
       "35463   -0.3255   6.2714   7.6188  10.2298   5.9419          0  \n",
       "51579    1.0350   9.7769   7.1368  19.6281   0.8843          0  \n",
       "165164  -1.2639   3.4729   8.1272  15.0752  -6.8129          0  \n",
       "125207  -0.6914   7.3110   9.4617  16.9748   6.4416          0  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.a.ii) Dimensions of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140000, 201)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy_train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.a.iii) Types of the attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 140000 entries, 62824 to 10750\n",
      "Columns: 201 entries, var_0 to targetVar\n",
      "dtypes: float64(200), int64(1)\n",
      "memory usage: 215.8 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "var_0        float64\n",
       "var_1        float64\n",
       "var_2        float64\n",
       "var_3        float64\n",
       "var_4        float64\n",
       "var_5        float64\n",
       "var_6        float64\n",
       "var_7        float64\n",
       "var_8        float64\n",
       "var_9        float64\n",
       "var_10       float64\n",
       "var_11       float64\n",
       "var_12       float64\n",
       "var_13       float64\n",
       "var_14       float64\n",
       "var_15       float64\n",
       "var_16       float64\n",
       "var_17       float64\n",
       "var_18       float64\n",
       "var_19       float64\n",
       "var_20       float64\n",
       "var_21       float64\n",
       "var_22       float64\n",
       "var_23       float64\n",
       "var_24       float64\n",
       "var_25       float64\n",
       "var_26       float64\n",
       "var_27       float64\n",
       "var_28       float64\n",
       "var_29       float64\n",
       "              ...   \n",
       "var_171      float64\n",
       "var_172      float64\n",
       "var_173      float64\n",
       "var_174      float64\n",
       "var_175      float64\n",
       "var_176      float64\n",
       "var_177      float64\n",
       "var_178      float64\n",
       "var_179      float64\n",
       "var_180      float64\n",
       "var_181      float64\n",
       "var_182      float64\n",
       "var_183      float64\n",
       "var_184      float64\n",
       "var_185      float64\n",
       "var_186      float64\n",
       "var_187      float64\n",
       "var_188      float64\n",
       "var_189      float64\n",
       "var_190      float64\n",
       "var_191      float64\n",
       "var_192      float64\n",
       "var_193      float64\n",
       "var_194      float64\n",
       "var_195      float64\n",
       "var_196      float64\n",
       "var_197      float64\n",
       "var_198      float64\n",
       "var_199      float64\n",
       "targetVar      int64\n",
       "Length: 201, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy_train_df.info()\n",
    "xy_train_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.a.iv) Statistical summary of all attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "      <th>targetVar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>140000.000000</td>\n",
       "      <td>140000.000000</td>\n",
       "      <td>140000.000000</td>\n",
       "      <td>140000.000000</td>\n",
       "      <td>140000.000000</td>\n",
       "      <td>140000.000000</td>\n",
       "      <td>140000.000000</td>\n",
       "      <td>140000.000000</td>\n",
       "      <td>140000.000000</td>\n",
       "      <td>140000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>140000.000000</td>\n",
       "      <td>140000.000000</td>\n",
       "      <td>140000.000000</td>\n",
       "      <td>140000.000000</td>\n",
       "      <td>140000.000000</td>\n",
       "      <td>140000.000000</td>\n",
       "      <td>140000.000000</td>\n",
       "      <td>140000.000000</td>\n",
       "      <td>140000.000000</td>\n",
       "      <td>140000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.681657</td>\n",
       "      <td>-1.622382</td>\n",
       "      <td>10.719087</td>\n",
       "      <td>6.793610</td>\n",
       "      <td>11.082699</td>\n",
       "      <td>-5.084031</td>\n",
       "      <td>5.408501</td>\n",
       "      <td>16.551609</td>\n",
       "      <td>0.282552</td>\n",
       "      <td>7.565824</td>\n",
       "      <td>...</td>\n",
       "      <td>7.440210</td>\n",
       "      <td>1.925769</td>\n",
       "      <td>3.331502</td>\n",
       "      <td>17.998757</td>\n",
       "      <td>-0.140089</td>\n",
       "      <td>2.290811</td>\n",
       "      <td>8.907276</td>\n",
       "      <td>15.874419</td>\n",
       "      <td>-3.324348</td>\n",
       "      <td>0.101421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.040667</td>\n",
       "      <td>4.047725</td>\n",
       "      <td>2.641914</td>\n",
       "      <td>2.043649</td>\n",
       "      <td>1.620770</td>\n",
       "      <td>7.863467</td>\n",
       "      <td>0.865468</td>\n",
       "      <td>3.418347</td>\n",
       "      <td>3.333568</td>\n",
       "      <td>1.235655</td>\n",
       "      <td>...</td>\n",
       "      <td>3.023324</td>\n",
       "      <td>1.478147</td>\n",
       "      <td>3.992782</td>\n",
       "      <td>3.133282</td>\n",
       "      <td>1.428656</td>\n",
       "      <td>5.446338</td>\n",
       "      <td>0.921585</td>\n",
       "      <td>3.009209</td>\n",
       "      <td>10.433128</td>\n",
       "      <td>0.301887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.408400</td>\n",
       "      <td>-14.696200</td>\n",
       "      <td>2.169300</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>5.074800</td>\n",
       "      <td>-32.562600</td>\n",
       "      <td>2.347300</td>\n",
       "      <td>5.749400</td>\n",
       "      <td>-10.505500</td>\n",
       "      <td>4.177100</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.918900</td>\n",
       "      <td>-3.814500</td>\n",
       "      <td>-10.845500</td>\n",
       "      <td>8.694400</td>\n",
       "      <td>-5.048100</td>\n",
       "      <td>-14.209600</td>\n",
       "      <td>6.047600</td>\n",
       "      <td>6.558700</td>\n",
       "      <td>-38.852800</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.460300</td>\n",
       "      <td>-4.728925</td>\n",
       "      <td>8.727600</td>\n",
       "      <td>5.251800</td>\n",
       "      <td>9.890600</td>\n",
       "      <td>-11.217600</td>\n",
       "      <td>4.767975</td>\n",
       "      <td>13.949400</td>\n",
       "      <td>-2.315100</td>\n",
       "      <td>6.617900</td>\n",
       "      <td>...</td>\n",
       "      <td>5.158175</td>\n",
       "      <td>0.889200</td>\n",
       "      <td>0.586600</td>\n",
       "      <td>15.640275</td>\n",
       "      <td>-1.167000</td>\n",
       "      <td>-1.958100</td>\n",
       "      <td>8.252000</td>\n",
       "      <td>13.834700</td>\n",
       "      <td>-11.199500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.524350</td>\n",
       "      <td>-1.604250</td>\n",
       "      <td>10.587000</td>\n",
       "      <td>6.825700</td>\n",
       "      <td>11.111450</td>\n",
       "      <td>-4.844500</td>\n",
       "      <td>5.385600</td>\n",
       "      <td>16.462500</td>\n",
       "      <td>0.389350</td>\n",
       "      <td>7.627400</td>\n",
       "      <td>...</td>\n",
       "      <td>7.352400</td>\n",
       "      <td>1.897750</td>\n",
       "      <td>3.393900</td>\n",
       "      <td>17.962900</td>\n",
       "      <td>-0.171200</td>\n",
       "      <td>2.396350</td>\n",
       "      <td>8.888400</td>\n",
       "      <td>15.937850</td>\n",
       "      <td>-2.817750</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.760800</td>\n",
       "      <td>1.362225</td>\n",
       "      <td>12.518000</td>\n",
       "      <td>8.319800</td>\n",
       "      <td>12.265700</td>\n",
       "      <td>0.924200</td>\n",
       "      <td>6.001725</td>\n",
       "      <td>19.106325</td>\n",
       "      <td>2.935500</td>\n",
       "      <td>8.584500</td>\n",
       "      <td>...</td>\n",
       "      <td>9.514600</td>\n",
       "      <td>2.941800</td>\n",
       "      <td>6.209925</td>\n",
       "      <td>20.395100</td>\n",
       "      <td>0.828200</td>\n",
       "      <td>6.543825</td>\n",
       "      <td>9.591625</td>\n",
       "      <td>18.064450</td>\n",
       "      <td>4.828825</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.315000</td>\n",
       "      <td>10.376800</td>\n",
       "      <td>19.353000</td>\n",
       "      <td>13.188300</td>\n",
       "      <td>16.671400</td>\n",
       "      <td>17.251600</td>\n",
       "      <td>8.285200</td>\n",
       "      <td>27.691800</td>\n",
       "      <td>10.151300</td>\n",
       "      <td>11.150600</td>\n",
       "      <td>...</td>\n",
       "      <td>16.716500</td>\n",
       "      <td>7.611600</td>\n",
       "      <td>17.908600</td>\n",
       "      <td>27.928800</td>\n",
       "      <td>4.272900</td>\n",
       "      <td>18.321500</td>\n",
       "      <td>12.000400</td>\n",
       "      <td>26.079100</td>\n",
       "      <td>27.531900</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               var_0          var_1          var_2          var_3  \\\n",
       "count  140000.000000  140000.000000  140000.000000  140000.000000   \n",
       "mean       10.681657      -1.622382      10.719087       6.793610   \n",
       "std         3.040667       4.047725       2.641914       2.043649   \n",
       "min         0.408400     -14.696200       2.169300       0.043000   \n",
       "25%         8.460300      -4.728925       8.727600       5.251800   \n",
       "50%        10.524350      -1.604250      10.587000       6.825700   \n",
       "75%        12.760800       1.362225      12.518000       8.319800   \n",
       "max        20.315000      10.376800      19.353000      13.188300   \n",
       "\n",
       "               var_4          var_5          var_6          var_7  \\\n",
       "count  140000.000000  140000.000000  140000.000000  140000.000000   \n",
       "mean       11.082699      -5.084031       5.408501      16.551609   \n",
       "std         1.620770       7.863467       0.865468       3.418347   \n",
       "min         5.074800     -32.562600       2.347300       5.749400   \n",
       "25%         9.890600     -11.217600       4.767975      13.949400   \n",
       "50%        11.111450      -4.844500       5.385600      16.462500   \n",
       "75%        12.265700       0.924200       6.001725      19.106325   \n",
       "max        16.671400      17.251600       8.285200      27.691800   \n",
       "\n",
       "               var_8          var_9      ...              var_191  \\\n",
       "count  140000.000000  140000.000000      ...        140000.000000   \n",
       "mean        0.282552       7.565824      ...             7.440210   \n",
       "std         3.333568       1.235655      ...             3.023324   \n",
       "min       -10.505500       4.177100      ...            -1.918900   \n",
       "25%        -2.315100       6.617900      ...             5.158175   \n",
       "50%         0.389350       7.627400      ...             7.352400   \n",
       "75%         2.935500       8.584500      ...             9.514600   \n",
       "max        10.151300      11.150600      ...            16.716500   \n",
       "\n",
       "             var_192        var_193        var_194        var_195  \\\n",
       "count  140000.000000  140000.000000  140000.000000  140000.000000   \n",
       "mean        1.925769       3.331502      17.998757      -0.140089   \n",
       "std         1.478147       3.992782       3.133282       1.428656   \n",
       "min        -3.814500     -10.845500       8.694400      -5.048100   \n",
       "25%         0.889200       0.586600      15.640275      -1.167000   \n",
       "50%         1.897750       3.393900      17.962900      -0.171200   \n",
       "75%         2.941800       6.209925      20.395100       0.828200   \n",
       "max         7.611600      17.908600      27.928800       4.272900   \n",
       "\n",
       "             var_196        var_197        var_198        var_199  \\\n",
       "count  140000.000000  140000.000000  140000.000000  140000.000000   \n",
       "mean        2.290811       8.907276      15.874419      -3.324348   \n",
       "std         5.446338       0.921585       3.009209      10.433128   \n",
       "min       -14.209600       6.047600       6.558700     -38.852800   \n",
       "25%        -1.958100       8.252000      13.834700     -11.199500   \n",
       "50%         2.396350       8.888400      15.937850      -2.817750   \n",
       "75%         6.543825       9.591625      18.064450       4.828825   \n",
       "max        18.321500      12.000400      26.079100      27.531900   \n",
       "\n",
       "           targetVar  \n",
       "count  140000.000000  \n",
       "mean        0.101421  \n",
       "std         0.301887  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 201 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy_train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.a.v) Count missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN in the dataframe columns:\n",
      " var_0        0\n",
      "var_1        0\n",
      "var_2        0\n",
      "var_3        0\n",
      "var_4        0\n",
      "var_5        0\n",
      "var_6        0\n",
      "var_7        0\n",
      "var_8        0\n",
      "var_9        0\n",
      "var_10       0\n",
      "var_11       0\n",
      "var_12       0\n",
      "var_13       0\n",
      "var_14       0\n",
      "var_15       0\n",
      "var_16       0\n",
      "var_17       0\n",
      "var_18       0\n",
      "var_19       0\n",
      "var_20       0\n",
      "var_21       0\n",
      "var_22       0\n",
      "var_23       0\n",
      "var_24       0\n",
      "var_25       0\n",
      "var_26       0\n",
      "var_27       0\n",
      "var_28       0\n",
      "var_29       0\n",
      "            ..\n",
      "var_171      0\n",
      "var_172      0\n",
      "var_173      0\n",
      "var_174      0\n",
      "var_175      0\n",
      "var_176      0\n",
      "var_177      0\n",
      "var_178      0\n",
      "var_179      0\n",
      "var_180      0\n",
      "var_181      0\n",
      "var_182      0\n",
      "var_183      0\n",
      "var_184      0\n",
      "var_185      0\n",
      "var_186      0\n",
      "var_187      0\n",
      "var_188      0\n",
      "var_189      0\n",
      "var_190      0\n",
      "var_191      0\n",
      "var_192      0\n",
      "var_193      0\n",
      "var_194      0\n",
      "var_195      0\n",
      "var_196      0\n",
      "var_197      0\n",
      "var_198      0\n",
      "var_199      0\n",
      "targetVar    0\n",
      "Length: 201, dtype: int64\n",
      "Total number of NaN in the dataframe:  0\n"
     ]
    }
   ],
   "source": [
    "print('Number of NaN in the dataframe columns:\\n', xy_train_df.isnull().sum())\n",
    "print('Total number of NaN in the dataframe: ', xy_train_df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.a.vi) Summarize the levels of the class attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "targetVar\n",
       "0    125801\n",
       "1     14199\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy_train_df.groupby('targetVar').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.b) Data visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.b.i) Univariate plots to better understand each attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms for each attribute\n",
    "# x_train_df.hist()\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Density plot for each attribute\n",
    "# x_train_df.plot(kind='density', subplots=True, layout=(dispRow,dispCol), sharex=False, sharey=False)\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box and Whisker plot for each attribute\n",
    "# x_train_df.plot(kind='box', subplots=True, layout=(dispRow,dispCol), sharex=False, sharey=False)\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.b.ii) Multivariate plots to better understand the relationships between attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot matrix\n",
    "# scatter_matrix(x_train_df)\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "# fig = pyplot.figure()\n",
    "# ax = fig.add_subplot(111)\n",
    "# correlations = x_train_df.corr(method='pearson')\n",
    "# cax = ax.matshow(correlations, vmin=-1, vmax=1)\n",
    "# fig.colorbar(cax)\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_notify(\"Data Summarization and Visualization completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3 - Prepare Data\n",
    "Some dataset may require additional preparation activities that will best exposes the structure of the problem and the relationships between the input attributes and the output variable. Some data-prep tasks might include:\n",
    "\n",
    "* Cleaning data by removing duplicates, marking missing values and even imputing missing values.\n",
    "* Feature selection where redundant features may be removed.\n",
    "* Data transforms where attributes are scaled or redistributed in order to best expose the structure of the problem later to learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_notify(\"Data Cleaning and Transformation has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.a) Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not applicable for this iteration of the project\n",
    "# Sample code for performing one-hot-encoding (Block #1 of 2)\n",
    "# According to the data dictionary, columns SOME_ATTR should be converted to categorical type\n",
    "# x_train_df['SOME_ATTR'] = x_train_df['SOME_ATTR'].astype('category')\n",
    "\n",
    "# # Apply the One-Hot-Encoding (dummy variable handling) technique\n",
    "# x_train_df = get_dummies(x_train_df)\n",
    "# print(x_train_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample code for performing one-hot-encoding (Block #2 of 2)\n",
    "# According to the data dictionary, columns SOME_ATTR should be converted to categorical type\n",
    "# x_train_df['SOME_ATTR'] = x_train_df['SOME_ATTR'].astype('category')\n",
    "\n",
    "# # Apply the One-Hot-Encoding (dummy variable handling) technique\n",
    "# x_test_df = get_dummies(x_test_df)\n",
    "# print(x_test_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.b) Data Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample code for performing SMOTE transformation on the training data (Block #1 of 2)\n",
    "# x_train_imbal = x_train_df.values\n",
    "# y_train_imbal = y_train_df.values.ravel()\n",
    "# print(\"x_train_imbal.shape: {} y_train_imbal.shape: {}\".format(x_train_imbal.shape, y_train_imbal.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample code for performing SMOTE transformation on the training data (Block #2 of 2)\n",
    "# print ('Original class distribution - 1: {} | 0: {}'.format((y_train_imbal==1).sum(), (y_train_imbal==0).sum()))\n",
    "# sm = SMOTE(random_state=seedNum)\n",
    "# x_train, y_train = sm.fit_sample(x_train_imbal, y_train_imbal)\n",
    "# print ('Resampled class distribution - 1: {} | 0: {}'.format((y_train==1).sum(), (y_train==0).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.c) Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample code for performing Attribute Importance Ranking (Block #1 of 3)\n",
    "# Feature Importance with Gradient Boosting Classifier\n",
    "# x_impVal = x_train_df.values\n",
    "# y_impVal = y_train_df.values.ravel()\n",
    "# model = GradientBoostingClassifier(random_state=seedNum)\n",
    "# model.fit(x_impVal, y_impVal)\n",
    "# importanceScore = model.feature_importances_\n",
    "# attributeList = x_train_df.columns.tolist()\n",
    "# attributeImportance = pd.DataFrame({'attribute': attributeList, 'importance': importanceScore})\n",
    "# rankedAttributes = attributeImportance.sort_values('importance', ascending=False)\n",
    "# print(rankedAttributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample code for performing Attribute Importance Ranking (Block #2 of 3)\n",
    "# Set the importance threshold and calculate the list of attributes that don't contribute to the importance threshold\n",
    "# importanceSum = sum(importanceScore)\n",
    "# maxThreshold = 0.99\n",
    "# i = 0\n",
    "# accumWeight = 0\n",
    "# exit_now = False\n",
    "# while ((i < totAttr) and (not exit_now)) :\n",
    "#     accumWeight = accumWeight + (rankedAttributes.iloc[i]['importance']/importanceSum)\n",
    "#     if (accumWeight >= maxThreshold) :\n",
    "#         exit_now = True\n",
    "#     else :\n",
    "#         i = i + 1\n",
    "# print('Number of attributes contributed to the importance threshold:'+str(i))\n",
    "# lowAttributes = rankedAttributes.iloc[(i):(totAttr),]['attribute'].tolist()\n",
    "# print('Number of attributes found to be of low importance:',len(lowAttributes))\n",
    "# print(lowAttributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample code for performing Attribute Importance Ranking (Block #3 of 3)\n",
    "# Removing the unselected attributes from the training and validation dataframes\n",
    "# x_train_df.drop(labels=lowAttributes, axis=1, inplace=True)\n",
    "# x_test_df.drop(labels=lowAttributes, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not applicable for this iteration of the project\n",
    "# Using the Logistic Regression algorithm, we perform the Recursive Feature Elimination (RFE) technique\n",
    "# x_rfeVal = x_train_df.values\n",
    "# y_rfeVal = y_train_df.values.ravel()\n",
    "# estimator = LogisticRegression(random_state=seedNum)\n",
    "# selector = RFE(estimator, 40)\n",
    "# selector = selector.fit(x_rfeVal, y_rfeVal)\n",
    "# print('The number of selected features:',selector.n_features_)\n",
    "# print('The mask of selected features:\\n',selector.support_)\n",
    "# print('The mask of selected features:\\n',selector.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the unselected attributes from the training dataframes\n",
    "# x_train_df = x_train_df[x_train_df.columns[selector.support_]]\n",
    "# print(x_train_df.shape)\n",
    "# x_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the unselected attributes from the validation dataframes\n",
    "# x_test_df = x_test_df[x_test_df.columns[selector.support_]]\n",
    "# print(x_test_df.shape)\n",
    "# x_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.d) Display the Final Datasets for Model-Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (140000, 200) y_train.shape: (140000,)\n",
      "x_test.shape: (60000, 200) y_test.shape: (60000,)\n"
     ]
    }
   ],
   "source": [
    "# We finalize the training and testing datasets for the modeling activities\n",
    "x_train = x_train_df.values\n",
    "y_train = y_train_df.values.ravel()\n",
    "x_test = x_test_df.values\n",
    "y_test = y_test_df.values.ravel()\n",
    "print(\"x_train.shape: {} y_train.shape: {}\".format(x_train.shape, y_train.shape))\n",
    "print(\"x_test.shape: {} y_test.shape: {}\".format(x_test.shape, y_test.shape))\n",
    "email_notify(\"Data Cleaning and Transformation completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model and Evaluate Algorithms\n",
    "After the data-prep, we next work on finding a workable model by evaluating a subset of machine learning algorithms that are good at exploiting the structure of the training. The typical evaluation tasks include:\n",
    "\n",
    "* Defining test options such as cross validation and the evaluation metric to use.\n",
    "* Spot checking a suite of linear and nonlinear machine learning algorithms.\n",
    "* Comparing the estimated accuracy of algorithms.\n",
    "\n",
    "For this project, we will evaluate one linear, two non-linear and four ensemble algorithms:\n",
    "\n",
    "Linear Algorithm: Logistic Regression\n",
    "\n",
    "Non-Linear Algorithms: Decision Trees (CART) and k-Nearest Neighbors\n",
    "\n",
    "Ensemble Algorithms: Bagged CART, Random Forest, Extra Trees, and Stochastic Gradient Boosting\n",
    "\n",
    "The random number seed is reset before each run to ensure that the evaluation of each algorithm is performed using the same data splits. It ensures the results are directly comparable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.a) Set test options and evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run algorithms using 10-fold cross validation\n",
    "num_folds = 10\n",
    "scoring = 'roc_auc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Algorithms Spot-Checking Array\n",
    "models = []\n",
    "# models.append(('LR', LogisticRegression(random_state=seedNum, solver='liblinear')))\n",
    "# models.append(('CART', DecisionTreeClassifier(random_state=seedNum)))\n",
    "# models.append(('KNN', KNeighborsClassifier()))\n",
    "# models.append(('BT', BaggingClassifier(random_state=seedNum)))\n",
    "# models.append(('RF', RandomForestClassifier(random_state=seedNum, n_estimators=100)))\n",
    "# models.append(('ET', ExtraTreesClassifier(random_state=seedNum)))\n",
    "models.append(('RUS', RUSBoostClassifier(random_state=seedNum)))\n",
    "results = []\n",
    "names = []\n",
    "metrics = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUS: 0.684450 (0.009098)\n",
      "Model training time: 0:37:38.454300\n",
      "Average metrics (roc_auc) from all models: 0.6844497111742068\n"
     ]
    }
   ],
   "source": [
    "# Generate model in turn\n",
    "for name, model in models:\n",
    "\temail_notify(\"Algorithm \"+name+\" modeling has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))\n",
    "\tstartTimeModule = datetime.now()\n",
    "\tkfold = KFold(n_splits=num_folds, random_state=seedNum)\n",
    "\tcv_results = cross_val_score(model, x_train, y_train, cv=kfold, scoring=scoring)\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tmetrics.append(cv_results.mean())\n",
    "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "\tprint(msg)\n",
    "\tprint ('Model training time:',(datetime.now() - startTimeModule))\n",
    "\temail_notify(\"Algorithm \"+name+\" modeling completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))\n",
    "print ('Average metrics ('+scoring+') from all models:',np.mean(metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.b) Spot-checking baseline algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = pyplot.figure()\n",
    "fig.suptitle('Algorithm Comparison - Spot Checking')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5 - Improve Accuracy\n",
    "After we achieve a short list of machine learning algorithms with good level of accuracy, we can leverage ways to improve the accuracy of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.a) Algorithm Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the comparison array\n",
    "results = []\n",
    "names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.686078 using {'n_estimators': 25}\n",
      "0.686078 (0.009192) with: {'n_estimators': 25}\n",
      "0.684450 (0.009098) with: {'n_estimators': 50}\n",
      "0.681538 (0.007567) with: {'n_estimators': 75}\n",
      "Model training time: 1:53:37.257104\n"
     ]
    }
   ],
   "source": [
    "# Tuning algorithm #1 - Stochastic Gradient Boosting\n",
    "email_notify(\"Algorithm tuning has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))\n",
    "startTimeModule = datetime.now()\n",
    "paramGrid1 = dict(n_estimators=np.array([25,50,75]))\n",
    "model1 = RUSBoostClassifier(random_state=seedNum)\n",
    "kfold = KFold(n_splits=num_folds, random_state=seedNum)\n",
    "grid1 = GridSearchCV(estimator=model1, param_grid=paramGrid1, scoring=scoring, cv=kfold)\n",
    "grid_result1 = grid1.fit(x_train, y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result1.best_score_, grid_result1.best_params_))\n",
    "results.append(grid_result1.cv_results_['mean_test_score'])\n",
    "names.append('RUS')\n",
    "means = grid_result1.cv_results_['mean_test_score']\n",
    "stds = grid_result1.cv_results_['std_test_score']\n",
    "params = grid_result1.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "print ('Model training time:',(datetime.now() - startTimeModule))\n",
    "email_notify(\"Algorithm tuning completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.b) Compare Algorithms After Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = pyplot.figure()\n",
    "fig.suptitle('Algorithm Comparison - Post Tuning')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6 - Finalize Model\n",
    "Once we have narrow down to a model that we believe can make accurate predictions on unseen data, we are ready to finalize it. Finalizing a model may involve sub-tasks such as:\n",
    "* Using an optimal model tuned to make predictions on unseen data.\n",
    "* Creating a standalone model using the tuned parameters\n",
    "* Saving an optimal model to file for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_notify(\"Model Validation and Final Model Creation has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.a) Predictions on validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalModel = RUSBoostClassifier(random_state=seedNum, n_estimators=25)\n",
    "finalModel.fit(x_train, y_train)\n",
    "predictions = finalModel.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC/AUC Score: 0.5681290246784628\n",
      "Accuracy Score: 0.849\n",
      "Confusion Matrix:\n",
      " [[49651  4450]\n",
      " [ 4610  1289]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92     54101\n",
      "           1       0.22      0.22      0.22      5899\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     60000\n",
      "   macro avg       0.57      0.57      0.57     60000\n",
      "weighted avg       0.85      0.85      0.85     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('ROC/AUC Score:',roc_auc_score(y_test, predictions))\n",
    "print('Accuracy Score:',accuracy_score(y_test, predictions))\n",
    "print('Confusion Matrix:\\n',confusion_matrix(y_test, predictions))\n",
    "print('Classification Report:\\n',classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.b) Prepare the Final Output File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_complete.shape: (200000, 200) y_complete.shape: (200000,)\n",
      "Model training time: 0:04:27.098717\n"
     ]
    }
   ],
   "source": [
    "startTimeModule = datetime.now()\n",
    "\n",
    "# Combining the training and testing datasets to form the complete dataset that will be used for training the final model\n",
    "x_complete = np.vstack((x_train, x_test))\n",
    "y_complete = np.concatenate((y_train, y_test))\n",
    "print(\"x_complete.shape: {} y_complete.shape: {}\".format(x_complete.shape, y_complete.shape))\n",
    "\n",
    "finalModel.fit(x_complete, y_complete)\n",
    "print ('Model training time:',(datetime.now() - startTimeModule))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFile = 'test.csv'\n",
    "x_validation_df = read_csv(inputFile, sep=',', index_col=False)\n",
    "\n",
    "y_submission_df = pd.DataFrame(columns=['ID_code','target'])\n",
    "y_submission_df['ID_code'] = x_validation_df['ID_code']\n",
    "x_validation_df.drop('ID_code',axis=1,inplace=True)\n",
    "# x_validation_df.drop(labels=lowAttributes, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_validation_df.shape: (200000, 200) y_submission_df.shape: (200000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_validation_df.shape: {} y_submission_df.shape: {}\".format(x_validation_df.shape, y_submission_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var_0    var_1    var_2   var_3    var_4   var_5   var_6    var_7  \\\n",
      "0  11.0656   7.7798  12.9536  9.4292  11.4327 -2.3805  5.8493  18.2675   \n",
      "1   8.5304   1.2543  11.3047  5.1858   9.1974 -4.0117  6.0196  18.6316   \n",
      "2   5.4827 -10.3581  10.1407  7.0479  10.2628  9.8052  4.8950  20.2537   \n",
      "3   8.5374  -1.3222  12.0220  6.5749   8.8458  3.1744  4.9397  20.5660   \n",
      "4  11.7058  -0.1327  14.1295  7.7506   9.1035 -8.5848  6.8595  10.6048   \n",
      "\n",
      "    var_8   var_9   ...     var_190  var_191  var_192  var_193  var_194  \\\n",
      "0  2.1337  8.8100   ...     -2.1556  11.8495  -1.4300   2.4508  13.7112   \n",
      "1 -4.4131  5.9739   ...     10.6165   8.8349   0.9403  10.1282  15.5765   \n",
      "2  1.5233  8.3442   ...     -0.7484  10.9935   1.9803   2.1800  12.9813   \n",
      "3  3.3755  7.4578   ...      9.5702   9.0766   1.6580   3.5813  15.1874   \n",
      "4  2.9890  7.1437   ...      4.2259   9.1723   1.2835   3.3778  19.5542   \n",
      "\n",
      "   var_195  var_196  var_197  var_198  var_199  \n",
      "0   2.4669   4.3654  10.7200  15.4722  -8.7197  \n",
      "1   0.4773  -1.4852   9.8714  19.1293 -20.9760  \n",
      "2   2.1281  -7.1086   7.0618  19.8956 -23.1794  \n",
      "3   3.1656   3.9567   9.2295  13.0168  -4.2108  \n",
      "4  -0.2860  -5.1612   7.2882  13.9260  -9.1846  \n",
      "\n",
      "[5 rows x 200 columns]\n"
     ]
    }
   ],
   "source": [
    "print(x_validation_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ID_code  target\n",
      "0  test_0       0\n",
      "1  test_1       0\n",
      "2  test_2       0\n",
      "3  test_3       0\n",
      "4  test_4       0\n"
     ]
    }
   ],
   "source": [
    "submissions = finalModel.predict(x_validation_df)\n",
    "y_submission_df['target'] = submissions\n",
    "print(y_submission_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    180607\n",
       "1     19393\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_submission_df.groupby('target').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_file = y_submission_df.to_csv(header=True,index=False)\n",
    "# filename = 'submission_' + datetime.now().strftime('%Y%m%d-%H%M') + '.csv'\n",
    "# with open(filename, 'w') as f:\n",
    "#     f.write(out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time for the script: 2:39:12.669864\n"
     ]
    }
   ],
   "source": [
    "email_notify(\"Model Validation and Final Model Creation completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))\n",
    "print ('Total time for the script:',(datetime.now() - startTimeScript))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
