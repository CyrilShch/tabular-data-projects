{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification Model for German Credit Risks Using Python Take 2\n",
    "### David Lowe\n",
    "### September 26, 2018\n",
    "\n",
    "Template Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery. https://machinelearningmastery.com/\n",
    "\n",
    "SUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The German Credit Risks Dataset is a binary-class classification situation where we are trying to predict one of the two possible outcomes.\n",
    "\n",
    "INTRODUCTION: This dataset contains 1,000 entries with 20 categorial/symbolic attributes prepared by Prof. Hofmann. In this dataset, each entry represents a person who takes on credit risk by a German bank. Each person is classified as good or bad credit risks according to the set of attributes.\n",
    "\n",
    "Because the case study also stipulated that it is worse to classify a customer as good when they are bad (weight of 5), than it is to classify a customer as bad when they are good (weight of 1). For this iteration, the script focuses on tuning various machine learning algorithms and identify the algorithm that can produce the best cost-and-accuracy tradeoffs.\n",
    "\n",
    "CONCLUSION: From the previous iteration Take 1, the baseline performance of the eight algorithms achieved an average accuracy of 71.80%. Three algorithms (Logistic Regression, Extra Trees, and Stochastic Gradient Boosting) achieved the top three accuracy scores after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top result using the training data. It achieved an average accuracy of 76.14%. Using the optimized tuning parameter available, the Stochastic Gradient Boosting algorithm processed the validation dataset with an accuracy of 77.66%, which was slightly better than the accuracy from the training data.\n",
    "\n",
    "From the cost vs accuracy comparison, both the Logistic Regression and Stochastic Gradient Boosting achieved high accuracy while keeping the costs of incorrect predictions low. Either algorithm should be considered for further modeling or production use.\n",
    "\n",
    "Dataset Used: German Credit Data Set\n",
    "\n",
    "Dataset ML Model: Binary classification with numerical and categorical attributes\n",
    "\n",
    "Dataset Reference: https://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29\n",
    "\n",
    "One potential source of performance benchmarks: https://www.kaggle.com/uciml/german-credit/home\n",
    "\n",
    "The project aims to touch on the following areas:\n",
    "\n",
    "* Document a predictive modeling problem end-to-end.\n",
    "* Explore data cleaning and transformation options\n",
    "* Explore non-ensemble and ensemble algorithms for baseline model performance\n",
    "* Explore algorithm tuning techniques for improving model performance\n",
    "\n",
    "Any predictive modeling machine learning project genrally can be broken down into about six major tasks:\n",
    "\n",
    "1. Prepare Problem\n",
    "2. Summarize Data\n",
    "3. Prepare Data\n",
    "4. Model and Evaluate Algorithms\n",
    "5. Improve Accuracy or Results\n",
    "6. Finalize Model and Present Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 - Prepare Problem\n",
    "### 1.a) Load ibraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import set_option\n",
    "from pandas import get_dummies\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.externals.joblib import dump\n",
    "from sklearn.externals.joblib import load\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.b) Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTimeScript = datetime.now()\n",
    "\n",
    "inputFile = 'german.data'\n",
    "colNames = [\"attr01\",\"attr02\",\"attr03\",\"attr04\",\"attr05\",\"attr06\",\"attr07\",\"attr08\",\"attr09\",\"attr10\",\"attr11\",\"attr12\",\"attr13\",\"attr14\",\"attr15\",\"attr16\",\"attr17\",\"attr18\",\"attr19\",\"attr20\",\"targetVar\"]\n",
    "entireDataset = read_csv(inputFile, delimiter=' ', names=colNames)\n",
    "\n",
    "# Re-label the class to \"0\" - Negative Class/Good Loan and \"1\" - Positive Class/Bad Loan\n",
    "entireDataset['targetVar'] = entireDataset['targetVar']-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.c) Set up the key parameters to be used in the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one random seed number for reproducible results\n",
    "seedNum = 777\n",
    "\n",
    "# Set up a variable for the total number of attribute columns (totAttr)\n",
    "totCol = len(entireDataset.columns)\n",
    "totAttr = totCol-1\n",
    "\n",
    "# Set up the number of row and columns for visualization display. dispRow * dispCol should be >= totAttr\n",
    "dispCol = 3\n",
    "if totAttr % dispCol == 0 :\n",
    "    dispRow = totAttr // dispCol\n",
    "else :\n",
    "    dispRow = (totAttr // dispCol) + 1\n",
    "    \n",
    "# Set figure width to 16 and height to 12 (4:3 aspect ratio)\n",
    "fig_size = pyplot.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 16\n",
    "fig_size[1] = 12\n",
    "pyplot.rcParams[\"figure.figsize\"] = fig_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 - Summarize Data\n",
    "To gain a better understanding of the data that we have on-hand, we will leverage a number of descriptive statistics and data visualization techniques. The plan is to use the results to consider new questions, review assumptions, and validate hypotheses that we can investigate later with specialized models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.a) Descriptive statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.a.i) Peek at the data itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   attr01  attr02 attr03 attr04  attr05 attr06 attr07  attr08 attr09 attr10  \\\n",
      "0     A11       6    A34    A43    1169    A65    A75       4    A93   A101   \n",
      "1     A12      48    A32    A43    5951    A61    A73       2    A92   A101   \n",
      "2     A14      12    A34    A46    2096    A61    A74       2    A93   A101   \n",
      "3     A11      42    A32    A42    7882    A61    A74       2    A93   A103   \n",
      "4     A11      24    A33    A40    4870    A61    A73       3    A93   A101   \n",
      "5     A14      36    A32    A46    9055    A65    A73       2    A93   A101   \n",
      "6     A14      24    A32    A42    2835    A63    A75       3    A93   A101   \n",
      "7     A12      36    A32    A41    6948    A61    A73       2    A93   A101   \n",
      "8     A14      12    A32    A43    3059    A64    A74       2    A91   A101   \n",
      "9     A12      30    A34    A40    5234    A61    A71       4    A94   A101   \n",
      "10    A12      12    A32    A40    1295    A61    A72       3    A92   A101   \n",
      "11    A11      48    A32    A49    4308    A61    A72       3    A92   A101   \n",
      "12    A12      12    A32    A43    1567    A61    A73       1    A92   A101   \n",
      "13    A11      24    A34    A40    1199    A61    A75       4    A93   A101   \n",
      "14    A11      15    A32    A40    1403    A61    A73       2    A92   A101   \n",
      "15    A11      24    A32    A43    1282    A62    A73       4    A92   A101   \n",
      "16    A14      24    A34    A43    2424    A65    A75       4    A93   A101   \n",
      "17    A11      30    A30    A49    8072    A65    A72       2    A93   A101   \n",
      "18    A12      24    A32    A41   12579    A61    A75       4    A92   A101   \n",
      "19    A14      24    A32    A43    3430    A63    A75       3    A93   A101   \n",
      "\n",
      "      ...     attr12 attr13  attr14 attr15 attr16  attr17 attr18  attr19  \\\n",
      "0     ...       A121     67    A143   A152      2    A173      1    A192   \n",
      "1     ...       A121     22    A143   A152      1    A173      1    A191   \n",
      "2     ...       A121     49    A143   A152      1    A172      2    A191   \n",
      "3     ...       A122     45    A143   A153      1    A173      2    A191   \n",
      "4     ...       A124     53    A143   A153      2    A173      2    A191   \n",
      "5     ...       A124     35    A143   A153      1    A172      2    A192   \n",
      "6     ...       A122     53    A143   A152      1    A173      1    A191   \n",
      "7     ...       A123     35    A143   A151      1    A174      1    A192   \n",
      "8     ...       A121     61    A143   A152      1    A172      1    A191   \n",
      "9     ...       A123     28    A143   A152      2    A174      1    A191   \n",
      "10    ...       A123     25    A143   A151      1    A173      1    A191   \n",
      "11    ...       A122     24    A143   A151      1    A173      1    A191   \n",
      "12    ...       A123     22    A143   A152      1    A173      1    A192   \n",
      "13    ...       A123     60    A143   A152      2    A172      1    A191   \n",
      "14    ...       A123     28    A143   A151      1    A173      1    A191   \n",
      "15    ...       A123     32    A143   A152      1    A172      1    A191   \n",
      "16    ...       A122     53    A143   A152      2    A173      1    A191   \n",
      "17    ...       A123     25    A141   A152      3    A173      1    A191   \n",
      "18    ...       A124     44    A143   A153      1    A174      1    A192   \n",
      "19    ...       A123     31    A143   A152      1    A173      2    A192   \n",
      "\n",
      "   attr20 targetVar  \n",
      "0    A201         0  \n",
      "1    A201         1  \n",
      "2    A201         0  \n",
      "3    A201         0  \n",
      "4    A201         1  \n",
      "5    A201         0  \n",
      "6    A201         0  \n",
      "7    A201         0  \n",
      "8    A201         0  \n",
      "9    A201         1  \n",
      "10   A201         1  \n",
      "11   A201         1  \n",
      "12   A201         0  \n",
      "13   A201         1  \n",
      "14   A201         0  \n",
      "15   A201         1  \n",
      "16   A201         0  \n",
      "17   A201         0  \n",
      "18   A201         1  \n",
      "19   A201         0  \n",
      "\n",
      "[20 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "print(entireDataset.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.a.ii) Dimensions of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 21)\n"
     ]
    }
   ],
   "source": [
    "print(entireDataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.a.iii) Types of the attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attr01       object\n",
      "attr02        int64\n",
      "attr03       object\n",
      "attr04       object\n",
      "attr05        int64\n",
      "attr06       object\n",
      "attr07       object\n",
      "attr08        int64\n",
      "attr09       object\n",
      "attr10       object\n",
      "attr11        int64\n",
      "attr12       object\n",
      "attr13        int64\n",
      "attr14       object\n",
      "attr15       object\n",
      "attr16        int64\n",
      "attr17       object\n",
      "attr18        int64\n",
      "attr19       object\n",
      "attr20       object\n",
      "targetVar     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(entireDataset.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.a.iv) Statistical summary of all attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            attr02        attr05       attr08       attr11       attr13  \\\n",
      "count  1000.000000   1000.000000  1000.000000  1000.000000  1000.000000   \n",
      "mean     20.903000   3271.258000     2.973000     2.845000    35.546000   \n",
      "std      12.058814   2822.736876     1.118715     1.103718    11.375469   \n",
      "min       4.000000    250.000000     1.000000     1.000000    19.000000   \n",
      "25%      12.000000   1365.500000     2.000000     2.000000    27.000000   \n",
      "50%      18.000000   2319.500000     3.000000     3.000000    33.000000   \n",
      "75%      24.000000   3972.250000     4.000000     4.000000    42.000000   \n",
      "max      72.000000  18424.000000     4.000000     4.000000    75.000000   \n",
      "\n",
      "            attr16       attr18    targetVar  \n",
      "count  1000.000000  1000.000000  1000.000000  \n",
      "mean      1.407000     1.155000     0.300000  \n",
      "std       0.577654     0.362086     0.458487  \n",
      "min       1.000000     1.000000     0.000000  \n",
      "25%       1.000000     1.000000     0.000000  \n",
      "50%       1.000000     1.000000     0.000000  \n",
      "75%       2.000000     1.000000     1.000000  \n",
      "max       4.000000     2.000000     1.000000  \n"
     ]
    }
   ],
   "source": [
    "print(entireDataset.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.a.v) Summarize the levels of the class attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targetVar\n",
      "0    700\n",
      "1    300\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(entireDataset.groupby('targetVar').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.a.v) Count missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attr01       0\n",
      "attr02       0\n",
      "attr03       0\n",
      "attr04       0\n",
      "attr05       0\n",
      "attr06       0\n",
      "attr07       0\n",
      "attr08       0\n",
      "attr09       0\n",
      "attr10       0\n",
      "attr11       0\n",
      "attr12       0\n",
      "attr13       0\n",
      "attr14       0\n",
      "attr15       0\n",
      "attr16       0\n",
      "attr17       0\n",
      "attr18       0\n",
      "attr19       0\n",
      "attr20       0\n",
      "targetVar    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(entireDataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3 - Prepare Data\n",
    "Some dataset may require additional preparation activities that will best exposes the structure of the problem and the relationships between the input attributes and the output variable. Some data-prep tasks might include:\n",
    "\n",
    "* Cleaning data by removing duplicates, marking missing values and even imputing missing values.\n",
    "* Feature selection where redundant features may be removed.\n",
    "* Data transforms where attributes are scaled or redistributed in order to best expose the structure of the problem later to learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.a) Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not applicable for this iteration of the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.b) Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not applicable for this iteration of the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.c) Data Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the string variables into categorical variables as appropriate\n",
    "entireDataset[\"attr01\"] = entireDataset[\"attr01\"].astype('category')\n",
    "entireDataset[\"attr03\"] = entireDataset[\"attr03\"].astype('category')\n",
    "entireDataset[\"attr04\"] = entireDataset[\"attr04\"].astype('category')\n",
    "entireDataset[\"attr06\"] = entireDataset[\"attr06\"].astype('category')\n",
    "entireDataset[\"attr07\"] = entireDataset[\"attr07\"].astype('category')\n",
    "entireDataset[\"attr09\"] = entireDataset[\"attr09\"].astype('category')\n",
    "entireDataset[\"attr10\"] = entireDataset[\"attr10\"].astype('category')\n",
    "entireDataset[\"attr12\"] = entireDataset[\"attr12\"].astype('category')\n",
    "entireDataset[\"attr14\"] = entireDataset[\"attr14\"].astype('category')\n",
    "entireDataset[\"attr15\"] = entireDataset[\"attr15\"].astype('category')\n",
    "entireDataset[\"attr17\"] = entireDataset[\"attr17\"].astype('category')\n",
    "entireDataset[\"attr19\"] = entireDataset[\"attr19\"].astype('category')\n",
    "entireDataset[\"attr20\"] = entireDataset[\"attr20\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attr02         int64\n",
      "attr05         int64\n",
      "attr08         int64\n",
      "attr11         int64\n",
      "attr13         int64\n",
      "attr16         int64\n",
      "attr18         int64\n",
      "targetVar      int64\n",
      "attr01_A11     uint8\n",
      "attr01_A12     uint8\n",
      "attr01_A13     uint8\n",
      "attr01_A14     uint8\n",
      "attr03_A30     uint8\n",
      "attr03_A31     uint8\n",
      "attr03_A32     uint8\n",
      "attr03_A33     uint8\n",
      "attr03_A34     uint8\n",
      "attr04_A40     uint8\n",
      "attr04_A41     uint8\n",
      "attr04_A410    uint8\n",
      "attr04_A42     uint8\n",
      "attr04_A43     uint8\n",
      "attr04_A44     uint8\n",
      "attr04_A45     uint8\n",
      "attr04_A46     uint8\n",
      "attr04_A48     uint8\n",
      "attr04_A49     uint8\n",
      "attr06_A61     uint8\n",
      "attr06_A62     uint8\n",
      "attr06_A63     uint8\n",
      "               ...  \n",
      "attr07_A71     uint8\n",
      "attr07_A72     uint8\n",
      "attr07_A73     uint8\n",
      "attr07_A74     uint8\n",
      "attr07_A75     uint8\n",
      "attr09_A91     uint8\n",
      "attr09_A92     uint8\n",
      "attr09_A93     uint8\n",
      "attr09_A94     uint8\n",
      "attr10_A101    uint8\n",
      "attr10_A102    uint8\n",
      "attr10_A103    uint8\n",
      "attr12_A121    uint8\n",
      "attr12_A122    uint8\n",
      "attr12_A123    uint8\n",
      "attr12_A124    uint8\n",
      "attr14_A141    uint8\n",
      "attr14_A142    uint8\n",
      "attr14_A143    uint8\n",
      "attr15_A151    uint8\n",
      "attr15_A152    uint8\n",
      "attr15_A153    uint8\n",
      "attr17_A171    uint8\n",
      "attr17_A172    uint8\n",
      "attr17_A173    uint8\n",
      "attr17_A174    uint8\n",
      "attr19_A191    uint8\n",
      "attr19_A192    uint8\n",
      "attr20_A201    uint8\n",
      "attr20_A202    uint8\n",
      "Length: 62, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Apply the One-Hot-Encoding (dummy variables handling) technique\n",
    "entireDataset_dummies = get_dummies(entireDataset)\n",
    "print(entireDataset_dummies.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange the columns so the targetVar column will appear first\n",
    "newcols = entireDataset_dummies.columns.tolist()\n",
    "newcols.insert(0, newcols.pop(newcols.index('targetVar')))\n",
    "entireDataset_dummies = entireDataset_dummies[newcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    targetVar  attr02  attr05  attr08  attr11  attr13  attr16  attr18  \\\n",
      "0           0       6    1169       4       4      67       2       1   \n",
      "1           1      48    5951       2       2      22       1       1   \n",
      "2           0      12    2096       2       3      49       1       2   \n",
      "3           0      42    7882       2       4      45       1       2   \n",
      "4           1      24    4870       3       4      53       2       2   \n",
      "5           0      36    9055       2       4      35       1       2   \n",
      "6           0      24    2835       3       4      53       1       1   \n",
      "7           0      36    6948       2       2      35       1       1   \n",
      "8           0      12    3059       2       4      61       1       1   \n",
      "9           1      30    5234       4       2      28       2       1   \n",
      "10          1      12    1295       3       1      25       1       1   \n",
      "11          1      48    4308       3       4      24       1       1   \n",
      "12          0      12    1567       1       1      22       1       1   \n",
      "13          1      24    1199       4       4      60       2       1   \n",
      "14          0      15    1403       2       4      28       1       1   \n",
      "15          1      24    1282       4       2      32       1       1   \n",
      "16          0      24    2424       4       4      53       2       1   \n",
      "17          0      30    8072       2       3      25       3       1   \n",
      "18          1      24   12579       4       2      44       1       1   \n",
      "19          0      24    3430       3       2      31       1       2   \n",
      "\n",
      "    attr01_A11  attr01_A12     ...       attr15_A152  attr15_A153  \\\n",
      "0            1           0     ...                 1            0   \n",
      "1            0           1     ...                 1            0   \n",
      "2            0           0     ...                 1            0   \n",
      "3            1           0     ...                 0            1   \n",
      "4            1           0     ...                 0            1   \n",
      "5            0           0     ...                 0            1   \n",
      "6            0           0     ...                 1            0   \n",
      "7            0           1     ...                 0            0   \n",
      "8            0           0     ...                 1            0   \n",
      "9            0           1     ...                 1            0   \n",
      "10           0           1     ...                 0            0   \n",
      "11           1           0     ...                 0            0   \n",
      "12           0           1     ...                 1            0   \n",
      "13           1           0     ...                 1            0   \n",
      "14           1           0     ...                 0            0   \n",
      "15           1           0     ...                 1            0   \n",
      "16           0           0     ...                 1            0   \n",
      "17           1           0     ...                 1            0   \n",
      "18           0           1     ...                 0            1   \n",
      "19           0           0     ...                 1            0   \n",
      "\n",
      "    attr17_A171  attr17_A172  attr17_A173  attr17_A174  attr19_A191  \\\n",
      "0             0            0            1            0            0   \n",
      "1             0            0            1            0            1   \n",
      "2             0            1            0            0            1   \n",
      "3             0            0            1            0            1   \n",
      "4             0            0            1            0            1   \n",
      "5             0            1            0            0            0   \n",
      "6             0            0            1            0            1   \n",
      "7             0            0            0            1            0   \n",
      "8             0            1            0            0            1   \n",
      "9             0            0            0            1            1   \n",
      "10            0            0            1            0            1   \n",
      "11            0            0            1            0            1   \n",
      "12            0            0            1            0            0   \n",
      "13            0            1            0            0            1   \n",
      "14            0            0            1            0            1   \n",
      "15            0            1            0            0            1   \n",
      "16            0            0            1            0            1   \n",
      "17            0            0            1            0            1   \n",
      "18            0            0            0            1            0   \n",
      "19            0            0            1            0            0   \n",
      "\n",
      "    attr19_A192  attr20_A201  attr20_A202  \n",
      "0             1            1            0  \n",
      "1             0            1            0  \n",
      "2             0            1            0  \n",
      "3             0            1            0  \n",
      "4             0            1            0  \n",
      "5             1            1            0  \n",
      "6             0            1            0  \n",
      "7             1            1            0  \n",
      "8             0            1            0  \n",
      "9             0            1            0  \n",
      "10            0            1            0  \n",
      "11            0            1            0  \n",
      "12            1            1            0  \n",
      "13            0            1            0  \n",
      "14            0            1            0  \n",
      "15            0            1            0  \n",
      "16            0            1            0  \n",
      "17            0            1            0  \n",
      "18            1            1            0  \n",
      "19            1            1            0  \n",
      "\n",
      "[20 rows x 62 columns]\n"
     ]
    }
   ],
   "source": [
    "print(entireDataset_dummies.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.d) Split-out training and validation datasets\n",
    "We create a training dataset (variable name \"training\") and a validation dataset (variable name \"validation\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_entire.shape: (1000, 61) Y_entire.shape: (1000,)\n",
      "X_train.shape: (700, 61) Y_train.shape: (700,)\n",
      "X_validation.shape: (300, 61) Y_validation.shape: (300,)\n",
      "Total time for data handling and visualization: 0:00:00.382780\n"
     ]
    }
   ],
   "source": [
    "# Determine the column offset of the targetVar column in dataframe\n",
    "# offset equals 0 if targetVar is the last column, offset equals 1 if targetVar is the first column\n",
    "offset = 1\n",
    "\n",
    "# Calculate the total number of attribute columns (non-class column)\n",
    "totAttr = len(entireDataset_dummies.columns)-1\n",
    "\n",
    "array = entireDataset_dummies.values\n",
    "X_entire = array[:,(0+offset):(totAttr+offset)]\n",
    "Y_entire = entireDataset_dummies['targetVar'].values\n",
    "validation_size = 0.30\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X_entire, Y_entire, test_size=validation_size, random_state=seedNum)\n",
    "print(\"X_entire.shape: {} Y_entire.shape: {}\".format(X_entire.shape, Y_entire.shape))\n",
    "print(\"X_train.shape: {} Y_train.shape: {}\".format(X_train.shape, Y_train.shape))\n",
    "print(\"X_validation.shape: {} Y_validation.shape: {}\".format(X_validation.shape, Y_validation.shape))\n",
    "print ('Total time for data handling and visualization:',(datetime.now() - startTimeScript))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model and Evaluate Algorithms\n",
    "After the data-prep, we next work on finding a workable model by evaluating a subset of machine learning algorithms that are good at exploiting the structure of the training. The typical evaluation tasks include:\n",
    "\n",
    "* Defining test options such as cross validation and the evaluation metric to use.\n",
    "* Spot checking a suite of linear and nonlinear machine learning algorithms.\n",
    "* Comparing the estimated accuracy of algorithms.\n",
    "\n",
    "For this project, we will evaluate one linear, four non-linear and five ensemble algorithms:\n",
    "\n",
    "Linear Algorithm: Logistic Regression\n",
    "\n",
    "Non-Linear Algorithms: Decision Trees (CART), Naive Bayes, k-Nearest Neighbors, and Support Vector Machine\n",
    "\n",
    "Ensemble Algorithms: Bagged CART, Random Forest, Extra Trees, AdaBoost, and Stochastic Gradient Boosting\n",
    "\n",
    "The random number seed is reset before each run to ensure that the evaluation of each algorithm is performed using the same data splits. It ensures the results are directly comparable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.a) Set test options and evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run algorithms using 10-fold cross validation\n",
    "num_folds = 10\n",
    "scoring = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the comparison array\n",
    "names = []\n",
    "results = []\n",
    "costs = []\n",
    "# Weight of 5 for false negative and weight of 1 for false positive\n",
    "weight_fn = 5\n",
    "weight_fp = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.b) Generate model and calculate costs - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7466666666666667\n",
      "[[183  37]\n",
      " [ 39  41]]\n",
      "The costs of wrong predictions:  232\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.83      0.83       220\n",
      "          1       0.53      0.51      0.52        80\n",
      "\n",
      "avg / total       0.74      0.75      0.75       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions using the best-tuned model possible\n",
    "startTimeModule = datetime.now()\n",
    "names.append('LR')\n",
    "model_LR = LogisticRegression(random_state=seedNum)\n",
    "model_LR.fit(X_train, Y_train)\n",
    "predictions_LR = model_LR.predict(X_validation)\n",
    "accuracy_LR = accuracy_score(Y_validation, predictions_LR)\n",
    "results.append(accuracy_LR)\n",
    "print(accuracy_LR)\n",
    "cm_LR = confusion_matrix(Y_validation, predictions_LR)\n",
    "# Calculate the costs of wrong predictions\n",
    "costs_LR = (cm_LR[0,1] * weight_fp) + (cm_LR[1,0] * weight_fn)\n",
    "print(cm_LR)\n",
    "print('The costs of wrong predictions: ',costs_LR)\n",
    "costs.append(costs_LR)\n",
    "print(classification_report(Y_validation, predictions_LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training and prediction time: 0:00:00.052968\n"
     ]
    }
   ],
   "source": [
    "print ('Model training and prediction time:',(datetime.now() - startTimeModule))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.c) Generate model and calculate costs - Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6766666666666666\n",
      "[[163  57]\n",
      " [ 40  40]]\n",
      "The costs of wrong predictions:  257\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.74      0.77       220\n",
      "          1       0.41      0.50      0.45        80\n",
      "\n",
      "avg / total       0.70      0.68      0.69       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions using the best-tuned model possible\n",
    "startTimeModule = datetime.now()\n",
    "names.append('CART')\n",
    "model_CART = DecisionTreeClassifier(random_state=seedNum)\n",
    "model_CART.fit(X_train, Y_train)\n",
    "predictions_CART = model_CART.predict(X_validation)\n",
    "accuracy_CART = accuracy_score(Y_validation, predictions_CART)\n",
    "results.append(accuracy_CART)\n",
    "print(accuracy_CART)\n",
    "cm_CART = confusion_matrix(Y_validation, predictions_CART)\n",
    "# Calculate the costs of wrong predictions\n",
    "costs_CART = (cm_CART[0,1] * weight_fp) + (cm_CART[1,0] * weight_fn)\n",
    "print(cm_CART)\n",
    "print('The costs of wrong predictions: ',costs_CART)\n",
    "costs.append(costs_CART)\n",
    "print(classification_report(Y_validation, predictions_CART))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.d) Generate model and calculate costs - Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7033333333333334\n",
      "[[162  58]\n",
      " [ 31  49]]\n",
      "The costs of wrong predictions:  213\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.74      0.78       220\n",
      "          1       0.46      0.61      0.52        80\n",
      "\n",
      "avg / total       0.74      0.70      0.72       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions using the best-tuned model possible\n",
    "startTimeModule = datetime.now()\n",
    "names.append('NB')\n",
    "model_NB = GaussianNB()\n",
    "model_NB.fit(X_train, Y_train)\n",
    "predictions_NB = model_NB.predict(X_validation)\n",
    "accuracy_NB = accuracy_score(Y_validation, predictions_NB)\n",
    "results.append(accuracy_NB)\n",
    "print(accuracy_NB)\n",
    "cm_NB = confusion_matrix(Y_validation, predictions_NB)\n",
    "# Calculate the costs of wrong predictions\n",
    "costs_NB = (cm_NB[0,1] * weight_fp) + (cm_NB[1,0] * weight_fn)\n",
    "print(cm_NB)\n",
    "print('The costs of wrong predictions: ',costs_NB)\n",
    "costs.append(costs_NB)\n",
    "print(classification_report(Y_validation, predictions_NB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.e) Generate model and calculate costs - k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.697143 using {'n_neighbors': 20}\n",
      "0.642857 (0.062922) with: {'n_neighbors': 5}\n",
      "0.674286 (0.070218) with: {'n_neighbors': 10}\n",
      "0.697143 (0.068452) with: {'n_neighbors': 20}\n",
      "0.688571 (0.073346) with: {'n_neighbors': 25}\n",
      "0.692857 (0.070927) with: {'n_neighbors': 30}\n",
      "Model training time: 0:00:00.586663\n"
     ]
    }
   ],
   "source": [
    "# Tuning algorithm - k-Nearest Neighbors\n",
    "startTimeModule = datetime.now()\n",
    "paramGrid = dict(n_neighbors=np.array([5,10,20,25,30]))\n",
    "model = KNeighborsClassifier()\n",
    "kfold = KFold(n_splits=num_folds, random_state=seedNum)\n",
    "grid = GridSearchCV(estimator=model, param_grid=paramGrid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "print ('Model training time:',(datetime.now() - startTimeModule))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74\n",
      "[[216   4]\n",
      " [ 74   6]]\n",
      "The costs of wrong predictions:  374\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.98      0.85       220\n",
      "          1       0.60      0.07      0.13        80\n",
      "\n",
      "avg / total       0.71      0.74      0.66       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions using the best-tuned model possible\n",
    "startTimeModule = datetime.now()\n",
    "names.append('KNN')\n",
    "model_KNN = KNeighborsClassifier(n_neighbors=20)\n",
    "model_KNN.fit(X_train, Y_train)\n",
    "predictions_KNN = model_KNN.predict(X_validation)\n",
    "accuracy_KNN = accuracy_score(Y_validation, predictions_KNN)\n",
    "results.append(accuracy_KNN)\n",
    "print(accuracy_KNN)\n",
    "cm_KNN = confusion_matrix(Y_validation, predictions_KNN)\n",
    "# Calculate the costs of wrong predictions\n",
    "costs_KNN = (cm_KNN[0,1] * weight_fp) + (cm_KNN[1,0] * weight_fn)\n",
    "print(cm_KNN)\n",
    "print('The costs of wrong predictions: ',costs_KNN)\n",
    "costs.append(costs_KNN)\n",
    "print(classification_report(Y_validation, predictions_KNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.f) Generate model and calculate costs - Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.674286 using {'C': 1}\n",
      "0.674286 (0.058484) with: {'C': 1}\n",
      "0.661429 (0.061958) with: {'C': 2}\n",
      "0.660000 (0.062532) with: {'C': 3}\n",
      "0.660000 (0.062532) with: {'C': 4}\n",
      "0.660000 (0.062532) with: {'C': 5}\n",
      "Model training time: 0:00:04.898189\n"
     ]
    }
   ],
   "source": [
    "# Tuning algorithm - Support Vector Machine\n",
    "startTimeModule = datetime.now()\n",
    "paramGrid = dict(C=np.array([1,2,3,4,5]))\n",
    "model = SVC()\n",
    "kfold = KFold(n_splits=num_folds, random_state=seedNum)\n",
    "grid = GridSearchCV(estimator=model, param_grid=paramGrid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "print ('Model training time:',(datetime.now() - startTimeModule))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72\n",
      "[[216   4]\n",
      " [ 80   0]]\n",
      "The costs of wrong predictions:  404\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.98      0.84       220\n",
      "          1       0.00      0.00      0.00        80\n",
      "\n",
      "avg / total       0.54      0.72      0.61       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions using the best-tuned model possible\n",
    "startTimeModule = datetime.now()\n",
    "names.append('SVM')\n",
    "model_SVM = SVC(C=1)\n",
    "model_SVM.fit(X_train, Y_train)\n",
    "predictions_SVM = model_SVM.predict(X_validation)\n",
    "accuracy_SVM = accuracy_score(Y_validation, predictions_SVM)\n",
    "results.append(accuracy_SVM)\n",
    "print(accuracy_SVM)\n",
    "cm_SVM = confusion_matrix(Y_validation, predictions_SVM)\n",
    "# Calculate the costs of wrong predictions\n",
    "costs_SVM = (cm_SVM[0,1] * weight_fp) + (cm_SVM[1,0] * weight_fn)\n",
    "print(cm_SVM)\n",
    "print('The costs of wrong predictions: ',costs_SVM)\n",
    "costs.append(costs_SVM)\n",
    "print(classification_report(Y_validation, predictions_SVM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.g) Generate model and calculate costs - Bagged CART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.754286 using {'n_estimators': 50}\n",
      "0.745714 (0.040305) with: {'n_estimators': 10}\n",
      "0.740000 (0.045535) with: {'n_estimators': 25}\n",
      "0.754286 (0.052216) with: {'n_estimators': 50}\n",
      "0.742857 (0.042857) with: {'n_estimators': 75}\n",
      "0.742857 (0.052683) with: {'n_estimators': 100}\n",
      "Model training time: 0:00:09.138755\n"
     ]
    }
   ],
   "source": [
    "# Tuning algorithm - Bagged CART\n",
    "startTimeModule = datetime.now()\n",
    "paramGrid = dict(n_estimators=np.array([10,25,50,75,100]))\n",
    "model = BaggingClassifier(random_state=seedNum)\n",
    "kfold = KFold(n_splits=num_folds, random_state=seedNum)\n",
    "grid = GridSearchCV(estimator=model, param_grid=paramGrid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "print ('Model training time:',(datetime.now() - startTimeModule))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7433333333333333\n",
      "[[188  32]\n",
      " [ 45  35]]\n",
      "The costs of wrong predictions:  257\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.85      0.83       220\n",
      "          1       0.52      0.44      0.48        80\n",
      "\n",
      "avg / total       0.73      0.74      0.74       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions using the best-tuned model possible\n",
    "startTimeModule = datetime.now()\n",
    "names.append('BT')\n",
    "model_BT = BaggingClassifier(n_estimators=50, random_state=seedNum)\n",
    "model_BT.fit(X_train, Y_train)\n",
    "predictions_BT = model_BT.predict(X_validation)\n",
    "accuracy_BT = accuracy_score(Y_validation, predictions_BT)\n",
    "results.append(accuracy_BT)\n",
    "print(accuracy_BT)\n",
    "cm_BT = confusion_matrix(Y_validation, predictions_BT)\n",
    "# Calculate the costs of wrong predictions\n",
    "costs_BT = (cm_BT[0,1] * weight_fp) + (cm_BT[1,0] * weight_fn)\n",
    "print(cm_BT)\n",
    "print('The costs of wrong predictions: ',costs_BT)\n",
    "costs.append(costs_BT)\n",
    "print(classification_report(Y_validation, predictions_BT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.h) Generate model and calculate costs - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.757143 using {'n_estimators': 75}\n",
      "0.732857 (0.043354) with: {'n_estimators': 25}\n",
      "0.747143 (0.040431) with: {'n_estimators': 50}\n",
      "0.757143 (0.036701) with: {'n_estimators': 75}\n",
      "0.755714 (0.041132) with: {'n_estimators': 100}\n",
      "0.747143 (0.045198) with: {'n_estimators': 150}\n",
      "Model training time: 0:00:06.416318\n"
     ]
    }
   ],
   "source": [
    "# Tuning algorithm - Random Forest\n",
    "startTimeModule = datetime.now()\n",
    "paramGrid = dict(n_estimators=np.array([25,50,75,100,150]))\n",
    "model = RandomForestClassifier(random_state=seedNum)\n",
    "kfold = KFold(n_splits=num_folds, random_state=seedNum)\n",
    "grid = GridSearchCV(estimator=model, param_grid=paramGrid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "print ('Model training time:',(datetime.now() - startTimeModule))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "[[193  27]\n",
      " [ 48  32]]\n",
      "The costs of wrong predictions:  267\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.88      0.84       220\n",
      "          1       0.54      0.40      0.46        80\n",
      "\n",
      "avg / total       0.73      0.75      0.74       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions using the best-tuned model possible\n",
    "startTimeModule = datetime.now()\n",
    "names.append('RF')\n",
    "model_RF = RandomForestClassifier(n_estimators=75, random_state=seedNum)\n",
    "model_RF.fit(X_train, Y_train)\n",
    "predictions_RF = model_RF.predict(X_validation)\n",
    "accuracy_RF = accuracy_score(Y_validation, predictions_RF)\n",
    "results.append(accuracy_RF)\n",
    "print(accuracy_RF)\n",
    "cm_RF = confusion_matrix(Y_validation, predictions_RF)\n",
    "# Calculate the costs of wrong predictions\n",
    "costs_RF = (cm_RF[0,1] * weight_fp) + (cm_RF[1,0] * weight_fn)\n",
    "print(cm_RF)\n",
    "print('The costs of wrong predictions: ',costs_RF)\n",
    "costs.append(costs_RF)\n",
    "print(classification_report(Y_validation, predictions_RF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.i) Generate model and calculate costs - Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.760000 using {'n_estimators': 25}\n",
      "0.747143 (0.050325) with: {'n_estimators': 10}\n",
      "0.760000 (0.051824) with: {'n_estimators': 25}\n",
      "0.748571 (0.057570) with: {'n_estimators': 50}\n",
      "0.754286 (0.039795) with: {'n_estimators': 75}\n",
      "0.750000 (0.047916) with: {'n_estimators': 100}\n",
      "Model training time: 0:00:04.270549\n"
     ]
    }
   ],
   "source": [
    "# Tuning algorithm - Extra Trees\n",
    "startTimeModule = datetime.now()\n",
    "paramGrid = dict(n_estimators=np.array([10,25,50,75,100]))\n",
    "model = ExtraTreesClassifier(random_state=seedNum)\n",
    "kfold = KFold(n_splits=num_folds, random_state=seedNum)\n",
    "grid = GridSearchCV(estimator=model, param_grid=paramGrid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "print ('Model training time:',(datetime.now() - startTimeModule))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74\n",
      "[[186  34]\n",
      " [ 44  36]]\n",
      "The costs of wrong predictions:  254\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.85      0.83       220\n",
      "          1       0.51      0.45      0.48        80\n",
      "\n",
      "avg / total       0.73      0.74      0.73       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions using the best-tuned model possible\n",
    "startTimeModule = datetime.now()\n",
    "names.append('ET')\n",
    "model_ET = ExtraTreesClassifier(n_estimators=25, random_state=seedNum)\n",
    "model_ET.fit(X_train, Y_train)\n",
    "predictions_ET = model_ET.predict(X_validation)\n",
    "accuracy_ET = accuracy_score(Y_validation, predictions_ET)\n",
    "results.append(accuracy_ET)\n",
    "print(accuracy_ET)\n",
    "cm_ET = confusion_matrix(Y_validation, predictions_ET)\n",
    "# Calculate the costs of wrong predictions\n",
    "costs_ET = (cm_ET[0,1] * weight_fp) + (cm_ET[1,0] * weight_fn)\n",
    "print(cm_ET)\n",
    "print('The costs of wrong predictions: ',costs_ET)\n",
    "costs.append(costs_ET)\n",
    "print(classification_report(Y_validation, predictions_ET))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.j) Generate model and calculate costs - AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.741429 using {'n_estimators': 25}\n",
      "0.707143 (0.052392) with: {'n_estimators': 10}\n",
      "0.741429 (0.048001) with: {'n_estimators': 25}\n",
      "0.740000 (0.054884) with: {'n_estimators': 50}\n",
      "0.741429 (0.051686) with: {'n_estimators': 75}\n",
      "0.730000 (0.049260) with: {'n_estimators': 100}\n",
      "Model training time: 0:00:04.503416\n"
     ]
    }
   ],
   "source": [
    "# Tuning algorithm - AdaBoost\n",
    "startTimeModule = datetime.now()\n",
    "paramGrid = dict(n_estimators=np.array([10,25,50,75,100]))\n",
    "model = AdaBoostClassifier(random_state=seedNum)\n",
    "kfold = KFold(n_splits=num_folds, random_state=seedNum)\n",
    "grid = GridSearchCV(estimator=model, param_grid=paramGrid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "print ('Model training time:',(datetime.now() - startTimeModule))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7466666666666667\n",
      "[[185  35]\n",
      " [ 41  39]]\n",
      "The costs of wrong predictions:  240\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.84      0.83       220\n",
      "          1       0.53      0.49      0.51        80\n",
      "\n",
      "avg / total       0.74      0.75      0.74       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions using the best-tuned model possible\n",
    "startTimeModule = datetime.now()\n",
    "names.append('ADA')\n",
    "model_ADA = AdaBoostClassifier(n_estimators=25, random_state=seedNum)\n",
    "model_ADA.fit(X_train, Y_train)\n",
    "predictions_ADA = model_ADA.predict(X_validation)\n",
    "accuracy_ADA = accuracy_score(Y_validation, predictions_ADA)\n",
    "results.append(accuracy_ADA)\n",
    "print(accuracy_ADA)\n",
    "cm_ADA = confusion_matrix(Y_validation, predictions_ADA)\n",
    "# Calculate the costs of wrong predictions\n",
    "costs_ADA = (cm_ADA[0,1] * weight_fp) + (cm_ADA[1,0] * weight_fn)\n",
    "print(cm_ADA)\n",
    "print('The costs of wrong predictions: ',costs_ADA)\n",
    "costs.append(costs_ADA)\n",
    "print(classification_report(Y_validation, predictions_ADA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.k) Generate model and calculate costs - Stochastic Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.768571 using {'n_estimators': 75}\n",
      "0.748571 (0.051981) with: {'n_estimators': 25}\n",
      "0.757143 (0.054958) with: {'n_estimators': 50}\n",
      "0.768571 (0.051429) with: {'n_estimators': 75}\n",
      "0.761429 (0.054977) with: {'n_estimators': 100}\n",
      "0.754286 (0.046861) with: {'n_estimators': 150}\n",
      "Model training time: 0:00:05.847643\n"
     ]
    }
   ],
   "source": [
    "# Tuning algorithm - Stochastic Gradient Boosting\n",
    "startTimeModule = datetime.now()\n",
    "paramGrid = dict(n_estimators=np.array([25,50,75,100,150]))\n",
    "model = GradientBoostingClassifier(random_state=seedNum)\n",
    "kfold = KFold(n_splits=num_folds, random_state=seedNum)\n",
    "grid = GridSearchCV(estimator=model, param_grid=paramGrid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "print ('Model training time:',(datetime.now() - startTimeModule))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7633333333333333\n",
      "[[193  27]\n",
      " [ 44  36]]\n",
      "The costs of wrong predictions:  247\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.88      0.84       220\n",
      "          1       0.57      0.45      0.50        80\n",
      "\n",
      "avg / total       0.75      0.76      0.75       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions using the best-tuned model possible\n",
    "startTimeModule = datetime.now()\n",
    "names.append('GBM')\n",
    "model_GBM = GradientBoostingClassifier(n_estimators=75, random_state=seedNum)\n",
    "model_GBM.fit(X_train, Y_train)\n",
    "predictions_GBM = model_GBM.predict(X_validation)\n",
    "accuracy_GBM = accuracy_score(Y_validation, predictions_GBM)\n",
    "results.append(accuracy_GBM)\n",
    "print(accuracy_GBM)\n",
    "cm_GBM = confusion_matrix(Y_validation, predictions_GBM)\n",
    "# Calculate the costs of wrong predictions\n",
    "costs_GBM = (cm_GBM[0,1] * weight_fp) + (cm_GBM[1,0] * weight_fn)\n",
    "print(cm_GBM)\n",
    "print('The costs of wrong predictions: ',costs_GBM)\n",
    "costs.append(costs_GBM)\n",
    "print(classification_report(Y_validation, predictions_GBM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5 - Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.a) Compare the accuracy of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x864 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = pyplot.figure()\n",
    "fig.suptitle('Model Accuracy Comparison')\n",
    "pyplot.bar(names, results)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.b) Compare the cost of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x864 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = pyplot.figure()\n",
    "fig.suptitle('Model Costs Comparison')\n",
    "pyplot.bar(names, costs)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.c) Plot the cost vs. accuracy of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x864 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = pyplot.subplots()\n",
    "fig.suptitle('Model Accuracy vs. Costs Comparison')\n",
    "ax.scatter(costs, results)\n",
    "for i, txt in enumerate(names):\n",
    "    ax.annotate(txt, (costs[i], results[i]))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time for the script: 0:00:37.898250\n"
     ]
    }
   ],
   "source": [
    "print ('Total time for the script:',(datetime.now() - startTimeScript))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
